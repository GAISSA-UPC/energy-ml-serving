{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  first selection\n",
    "\n",
    "- text-generation []\n",
    "- decoder []\n",
    "\n",
    "- open-source models [x]\n",
    "- HF availability [x]\n",
    "- Task: text generation [x]\n",
    "- Date []\n",
    "- architecture: decoder-based only,  []\n",
    "- model size < SLMs size [x]\n",
    "  - https://huggingface.co/docs/accelerate/main/en/usage_guides/model_size_estimator?\n",
    "  - model size from endpoint?\n",
    "  - safetensors -> model_info.safetensors -> https://huggingface.co/microsoft/phi-2 [x]\n",
    "  - check it matches our data about models used []\n",
    "\n",
    "- [?]Code generation [] used in code generation, trained in code datasets?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/fjdur/energy-ml-serving'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"model_selection/\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'model_selection/tmp/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get first dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize API\n",
    "api = HfApi()\n",
    "\n",
    "# Fetch models metadata\n",
    "limit = 20\n",
    "models = api.list_models(task=\"text-generation\", pipeline_tag=\"text-generation\",sort=\"downloads\", limit=limit)\n",
    "#models = api.list_models(task=\"text-generation\", sort=\"downloads\", limit=500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-->\n",
      "model_id: openai-community/gpt2\n",
      "config: {'architectures': ['GPT2LMHeadModel'], 'model_type': 'gpt2', 'tokenizer_config': {}}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ModelInfo' object has no attribute 'downloads_all_time'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m model_info \u001b[38;5;241m=\u001b[39m api\u001b[38;5;241m.\u001b[39mmodel_info(model\u001b[38;5;241m.\u001b[39mmodelId)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_info\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mmodel_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownloads_all_time\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md2: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_info\u001b[38;5;241m.\u001b[39mdownloads\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#print(f'gguf: {model_info.gguf}')\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ModelInfo' object has no attribute 'downloads_all_time'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Filter for decoder-only architectures\n",
    "decoder_models = []\n",
    "i = 0\n",
    "num_models = 200000\n",
    "\n",
    "for model in models:\n",
    "    print(f\"{i}-->\")\n",
    "    if i > num_models:\n",
    "        print(\"breaking\")\n",
    "        break\n",
    "\n",
    "    model_id = getattr(model, \"modelId\", \"Unknown\")\n",
    "    print(f'model_id: {model_id}')\n",
    "\n",
    "    # Fetch detailed model information\n",
    "    model_info = api.model_info(model.modelId)\n",
    "    print(f'config: {model_info.config}')\n",
    "    print(f'd1: {model_info.downloads_all_time}')\n",
    "    print(f'd2: {model_info.downloads}')\n",
    "    #print(f'gguf: {model_info.gguf}')\n",
    "    print(f'safetensors: {model_info.safetensors}')\n",
    "\n",
    "\n",
    "\n",
    "    if model_info.config ==None:\n",
    "        continue\n",
    "\n",
    "    # Collect model metadata with the desired column names\n",
    "    model_metadata = {\n",
    "        #\"model\": model.modelId,  # Model name or ID\n",
    "        \"model\": getattr(model, \"modelId\", \"Unknown\"),\n",
    "\n",
    "        \"id\": getattr(model, \"modelId\", \"Unknown\"),\n",
    "        #\"downloads_all_time\": getattr(model_info, \"downloads_all_time\", \"Unknown\"),\n",
    "        \"downloads\": getattr(model_info, \"downloads\", \"Unknown\"),\n",
    "        \"safetensors\": getattr(model_info, \"safetensors\", \"Unknown\"),\n",
    "\n",
    "        \"tags\": getattr(model, \"tags\", \"Unknown\"),\n",
    "        \"task\": getattr(model_info, \"pipeline_tag\", \"Unknown\"),\n",
    "        \"card_data\": getattr(model_info, \"card_data\", \"Unknown\"),\n",
    "        \"created_at\": getattr(model, \"created_at\", \"Unknown\"),\n",
    "        \"library_name\": getattr(model, \"library_name\", \"Unknown\"),\n",
    "        \"transformers_info\": getattr(model_info, \"transformers_info\", \"Unknown\"),\n",
    "        \"architecture\": model_info.config.get(\"architectures\", \"Unknown\")\n",
    "    }\n",
    "    print(f'model_metadata: {model_metadata}')\n",
    "\n",
    "    decoder_models.append(model_metadata)\n",
    "    i += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key 'safetensors' in item at index 5 has a value of None.\n",
      "Key 'safetensors' in item at index 6 has a value of None.\n"
     ]
    }
   ],
   "source": [
    "# Check for inconsistencies\n",
    "for index, item in enumerate(decoder_models):\n",
    "    if not isinstance(item, dict):\n",
    "        print(f\"Item at index {index} is not a dictionary: {item}\")\n",
    "    else:\n",
    "        # Check for problematic keys or data\n",
    "        for key, value in item.items():\n",
    "            if value is None:\n",
    "                print(f\"Key '{key}' in item at index {index} has a value of None.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame created successfully\n"
     ]
    }
   ],
   "source": [
    "# Attempt to create the DataFrame in a simplified way\n",
    "try:\n",
    "    df = pd.DataFrame(decoder_models)\n",
    "    print(\"DataFrame created successfully\")\n",
    "    #print(df.head())  # Display only the first few rows to avoid rendering issues\n",
    "except Exception as e:\n",
    "    print(f\"Error creating DataFrame: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved: decoder_models.csv\n"
     ]
    }
   ],
   "source": [
    "# used python script\n",
    "\n",
    "#df.to_csv(\"decoder_models.csv\", index=False)\n",
    "#print(\"CSV file saved: decoder_models.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['model', 'id', 'downloads', 'safetensors', 'tags', 'task', 'created_at',\n",
       "       'library_name', 'transformers_info', 'architecture'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2024-09-17 14:10:29+00:00\n",
       "1    2022-03-02 23:29:04+00:00\n",
       "2    2024-07-16 01:29:54+00:00\n",
       "3    2024-07-16 08:07:29+00:00\n",
       "4    2022-10-08 16:14:42+00:00\n",
       "5    2022-05-11 08:25:17+00:00\n",
       "6    2024-07-18 08:56:00+00:00\n",
       "7    2022-03-02 23:29:04+00:00\n",
       "8    2024-07-16 16:07:46+00:00\n",
       "9    2024-04-17 09:35:12+00:00\n",
       "10   2023-02-08 15:12:33+00:00\n",
       "11   2023-03-29 07:11:13+00:00\n",
       "12   2024-09-18 15:12:47+00:00\n",
       "13   2024-07-04 10:15:41+00:00\n",
       "14   2023-07-13 16:16:13+00:00\n",
       "15   2024-09-18 15:03:14+00:00\n",
       "16   2023-12-30 06:27:30+00:00\n",
       "17   2024-10-22 15:44:28+00:00\n",
       "18   2023-06-17 19:52:11+00:00\n",
       "19   2022-03-02 23:29:04+00:00\n",
       "Name: created_at, dtype: datetime64[ns, UTC]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['created_at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total models: 104816\n"
     ]
    }
   ],
   "source": [
    "file_name = 'model_selection/results/decoder_models_info_02.csv'\n",
    "df = pd.read_csv(file_name)\n",
    "print(f'total models: {len(df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]['safetensors']\n",
    "df.iloc[0]['eval_results']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['model', 'id', 'created_at', 'downloads_all_time', 'downloads', 'likes',\n",
       "       'safetensors', 'task', 'datasets', 'eval_results', 'metrics',\n",
       "       'library_name', 'transformers_info', 'architecture', 'tags',\n",
       "       'card_data'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After safetensors check:  67761\n",
      "After eval_results check:  8011\n",
      "8011\n",
      "After eval_results second check:  1933\n",
      "1933\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Filter out rows where the 'safetensors' column is NaN\n",
    "filtered_df = df[df['safetensors'].notna()]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(\"After safetensors check: \",len(filtered_df))\n",
    "\n",
    "# Filter out rows where the 'safetensors' column is NaN\n",
    "filtered_df = filtered_df[filtered_df['eval_results'].notna() ]\n",
    "\n",
    "print(\"After eval_results check: \",len(filtered_df))\n",
    "\n",
    "# # Ensure 'eval_results' is not an empty list\n",
    "# filtered_df = filtered_df[\n",
    "#     filtered_df['eval_results'].apply(lambda x: not isinstance(x, list) or (isinstance(x, list) and len(x) > 0) or (isinstance(x, str) and x != \"[]\"))\n",
    "# ]\n",
    "\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(len(filtered_df))\n",
    "\n",
    "# Ensure 'eval_results' is not an empty list or stringified empty list\n",
    "filtered_df = filtered_df[\n",
    "    filtered_df['eval_results'].apply(\n",
    "        lambda x: not (isinstance(x, list) and len(x) == 0) and x != \"[]\" and pd.notna(x)\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"After eval_results second check: \",len(filtered_df))\n",
    "\n",
    "# Display the length of the filtered DataFrame\n",
    "print(len(filtered_df))\n",
    "\n",
    "\n",
    "save_evaluated_df =False\n",
    "if save_evaluated_df:\n",
    "    # Optional: Save the filtered DataFrame to a CSV file\n",
    "    filtered_df.to_csv(save_dir + \"evaluated_models.csv\", index=False)\n",
    "    print(f\"Filtered CSV file saved: {save_dir}evaluated_models.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "[EvalResult(task_type='text-generation', dataset_type='openai_humaneval', dataset_name='humaneval', metric_type='pass@1', metric_value=0.15542682926829265, task_name=None, dataset_config=None, dataset_split=None, dataset_revision=None, dataset_args=None, metric_name='pass@1', metric_config=None, metric_args=None, verified=False, verify_token=None, source_name=None, source_url=None), EvalResult(task_type='text-generation', dataset_type='openai_humaneval', dataset_name='humaneval', metric_type='pass@10', metric_value=0.3278356276947017, task_name=None, dataset_config=None, dataset_split=None, dataset_revision=None, dataset_args=None, metric_name='pass@10', metric_config=None, metric_args=None, verified=False, verify_token=None, source_name=None, source_url=None), EvalResult(task_type='text-generation', dataset_type='openai_humaneval', dataset_name='humaneval', metric_type='pass@100', metric_value=0.5719815685597749, task_name=None, dataset_config=None, dataset_split=None, dataset_revision=None, dataset_args=None, metric_name='pass@100', metric_config=None, metric_args=None, verified=False, verify_token=None, source_name=None, source_url=None)]\n",
      "1159\n"
     ]
    }
   ],
   "source": [
    "print(type(filtered_df.iloc[2]['eval_results']))\n",
    "print(filtered_df.iloc[2]['eval_results'])\n",
    "print(len(filtered_df.iloc[2]['eval_results']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>downloads_all_time</th>\n",
       "      <th>downloads</th>\n",
       "      <th>likes</th>\n",
       "      <th>safetensors</th>\n",
       "      <th>task</th>\n",
       "      <th>datasets</th>\n",
       "      <th>eval_results</th>\n",
       "      <th>metrics</th>\n",
       "      <th>library_name</th>\n",
       "      <th>transformers_info</th>\n",
       "      <th>architecture</th>\n",
       "      <th>tags</th>\n",
       "      <th>card_data</th>\n",
       "      <th>num_parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ibm-granite/granite-3.0-8b-instruct</td>\n",
       "      <td>ibm-granite/granite-3.0-8b-instruct</td>\n",
       "      <td>2024-10-02 21:16:23+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>19349</td>\n",
       "      <td>148</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 8170848256...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[EvalResult(task_type='text-generation', datas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['GraniteForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'granite', 'te...</td>\n",
       "      <td>license: apache-2.0\\nlibrary_name: transformer...</td>\n",
       "      <td>8170848256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>arcee-ai/SuperNova-Medius</td>\n",
       "      <td>arcee-ai/SuperNova-Medius</td>\n",
       "      <td>2024-10-02 06:50:01+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>7777</td>\n",
       "      <td>160</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 1477003366...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[EvalResult(task_type='text-generation', datas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['Qwen2ForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'qwen2', 'text...</td>\n",
       "      <td>license: apache-2.0\\nlibrary_name: transformer...</td>\n",
       "      <td>14770033664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>bigscience/bloom</td>\n",
       "      <td>bigscience/bloom</td>\n",
       "      <td>2022-05-19 11:53:33+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>10666</td>\n",
       "      <td>4760</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 1762472714...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[EvalResult(task_type='text-generation', datas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['BloomForCausalLM']</td>\n",
       "      <td>['transformers', 'pytorch', 'tensorboard', 'sa...</td>\n",
       "      <td>language:\\n- ak\\n- ar\\n- as\\n- bm\\n- bn\\n- ca\\...</td>\n",
       "      <td>176247271424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>dfurman/CalmeRys-78B-Orpo-v0.1</td>\n",
       "      <td>dfurman/CalmeRys-78B-Orpo-v0.1</td>\n",
       "      <td>2024-09-24 10:25:46+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>5470</td>\n",
       "      <td>35</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 7796546355...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>['mlabonne/orpo-dpo-mix-40k']</td>\n",
       "      <td>[EvalResult(task_type='text-generation', datas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['Qwen2ForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'qwen2', 'text...</td>\n",
       "      <td>language:\\n- en\\nlicense: mit\\nlibrary_name: t...</td>\n",
       "      <td>77965463552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Orenguteng/Llama-3.1-8B-Lexi-Uncensored-V2</td>\n",
       "      <td>Orenguteng/Llama-3.1-8B-Lexi-Uncensored-V2</td>\n",
       "      <td>2024-08-09 20:39:15+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>29053</td>\n",
       "      <td>87</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 8030261248...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[EvalResult(task_type='text-generation', datas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['LlamaForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'llama', 'text...</td>\n",
       "      <td>license: llama3.1\\nlibrary_name: transformers\\...</td>\n",
       "      <td>8030261248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         model  \\\n",
       "18         ibm-granite/granite-3.0-8b-instruct   \n",
       "40                   arcee-ai/SuperNova-Medius   \n",
       "46                            bigscience/bloom   \n",
       "64              dfurman/CalmeRys-78B-Orpo-v0.1   \n",
       "72  Orenguteng/Llama-3.1-8B-Lexi-Uncensored-V2   \n",
       "\n",
       "                                            id                 created_at  \\\n",
       "18         ibm-granite/granite-3.0-8b-instruct  2024-10-02 21:16:23+00:00   \n",
       "40                   arcee-ai/SuperNova-Medius  2024-10-02 06:50:01+00:00   \n",
       "46                            bigscience/bloom  2022-05-19 11:53:33+00:00   \n",
       "64              dfurman/CalmeRys-78B-Orpo-v0.1  2024-09-24 10:25:46+00:00   \n",
       "72  Orenguteng/Llama-3.1-8B-Lexi-Uncensored-V2  2024-08-09 20:39:15+00:00   \n",
       "\n",
       "   downloads_all_time  downloads  likes  \\\n",
       "18            Unknown      19349    148   \n",
       "40            Unknown       7777    160   \n",
       "46            Unknown      10666   4760   \n",
       "64            Unknown       5470     35   \n",
       "72            Unknown      29053     87   \n",
       "\n",
       "                                          safetensors             task  \\\n",
       "18  SafeTensorsInfo(parameters={'BF16': 8170848256...  text-generation   \n",
       "40  SafeTensorsInfo(parameters={'BF16': 1477003366...  text-generation   \n",
       "46  SafeTensorsInfo(parameters={'BF16': 1762472714...  text-generation   \n",
       "64  SafeTensorsInfo(parameters={'BF16': 7796546355...  text-generation   \n",
       "72  SafeTensorsInfo(parameters={'BF16': 8030261248...  text-generation   \n",
       "\n",
       "                         datasets  \\\n",
       "18                            NaN   \n",
       "40                            NaN   \n",
       "46                            NaN   \n",
       "64  ['mlabonne/orpo-dpo-mix-40k']   \n",
       "72                            NaN   \n",
       "\n",
       "                                         eval_results metrics  library_name  \\\n",
       "18  [EvalResult(task_type='text-generation', datas...     NaN  transformers   \n",
       "40  [EvalResult(task_type='text-generation', datas...     NaN  transformers   \n",
       "46  [EvalResult(task_type='text-generation', datas...     NaN  transformers   \n",
       "64  [EvalResult(task_type='text-generation', datas...     NaN  transformers   \n",
       "72  [EvalResult(task_type='text-generation', datas...     NaN  transformers   \n",
       "\n",
       "                                    transformers_info            architecture  \\\n",
       "18  TransformersInfo(auto_model='AutoModelForCausa...  ['GraniteForCausalLM']   \n",
       "40  TransformersInfo(auto_model='AutoModelForCausa...    ['Qwen2ForCausalLM']   \n",
       "46  TransformersInfo(auto_model='AutoModelForCausa...    ['BloomForCausalLM']   \n",
       "64  TransformersInfo(auto_model='AutoModelForCausa...    ['Qwen2ForCausalLM']   \n",
       "72  TransformersInfo(auto_model='AutoModelForCausa...    ['LlamaForCausalLM']   \n",
       "\n",
       "                                                 tags  \\\n",
       "18  ['transformers', 'safetensors', 'granite', 'te...   \n",
       "40  ['transformers', 'safetensors', 'qwen2', 'text...   \n",
       "46  ['transformers', 'pytorch', 'tensorboard', 'sa...   \n",
       "64  ['transformers', 'safetensors', 'qwen2', 'text...   \n",
       "72  ['transformers', 'safetensors', 'llama', 'text...   \n",
       "\n",
       "                                            card_data  num_parameters  \n",
       "18  license: apache-2.0\\nlibrary_name: transformer...      8170848256  \n",
       "40  license: apache-2.0\\nlibrary_name: transformer...     14770033664  \n",
       "46  language:\\n- ak\\n- ar\\n- as\\n- bm\\n- bn\\n- ca\\...    176247271424  \n",
       "64  language:\\n- en\\nlicense: mit\\nlibrary_name: t...     77965463552  \n",
       "72  license: llama3.1\\nlibrary_name: transformers\\...      8030261248  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding num_parameters column\n",
    "\n",
    "# Function to extract the 'total' value from the 'safetensors' string\n",
    "def extract_total(safetensors_info):\n",
    "    if pd.isna(safetensors_info):\n",
    "        return None\n",
    "    match = re.search(r\"total=(\\d+)\", safetensors_info)\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "# Create a new column 'num_parameters' with the extracted total\n",
    "filtered_df['num_parameters'] = filtered_df['safetensors'].apply(extract_total)\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "likes max: 4760 downloads max: 12174074\n",
      "popularity max: 1.0220588235294117 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>downloads_all_time</th>\n",
       "      <th>downloads</th>\n",
       "      <th>likes</th>\n",
       "      <th>safetensors</th>\n",
       "      <th>task</th>\n",
       "      <th>datasets</th>\n",
       "      <th>eval_results</th>\n",
       "      <th>metrics</th>\n",
       "      <th>library_name</th>\n",
       "      <th>transformers_info</th>\n",
       "      <th>architecture</th>\n",
       "      <th>tags</th>\n",
       "      <th>card_data</th>\n",
       "      <th>num_parameters</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ibm-granite/granite-3.0-8b-instruct</td>\n",
       "      <td>ibm-granite/granite-3.0-8b-instruct</td>\n",
       "      <td>2024-10-02 21:16:23+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>19349</td>\n",
       "      <td>148</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 8170848256...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[EvalResult(task_type='text-generation', datas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['GraniteForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'granite', 'te...</td>\n",
       "      <td>license: apache-2.0\\nlibrary_name: transformer...</td>\n",
       "      <td>8170848256</td>\n",
       "      <td>0.032682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>arcee-ai/SuperNova-Medius</td>\n",
       "      <td>arcee-ai/SuperNova-Medius</td>\n",
       "      <td>2024-10-02 06:50:01+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>7777</td>\n",
       "      <td>160</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 1477003366...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[EvalResult(task_type='text-generation', datas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['Qwen2ForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'qwen2', 'text...</td>\n",
       "      <td>license: apache-2.0\\nlibrary_name: transformer...</td>\n",
       "      <td>14770033664</td>\n",
       "      <td>0.034252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>bigscience/bloom</td>\n",
       "      <td>bigscience/bloom</td>\n",
       "      <td>2022-05-19 11:53:33+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>10666</td>\n",
       "      <td>4760</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 1762472714...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[EvalResult(task_type='text-generation', datas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['BloomForCausalLM']</td>\n",
       "      <td>['transformers', 'pytorch', 'tensorboard', 'sa...</td>\n",
       "      <td>language:\\n- ak\\n- ar\\n- as\\n- bm\\n- bn\\n- ca\\...</td>\n",
       "      <td>176247271424</td>\n",
       "      <td>1.000876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>dfurman/CalmeRys-78B-Orpo-v0.1</td>\n",
       "      <td>dfurman/CalmeRys-78B-Orpo-v0.1</td>\n",
       "      <td>2024-09-24 10:25:46+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>5470</td>\n",
       "      <td>35</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 7796546355...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>['mlabonne/orpo-dpo-mix-40k']</td>\n",
       "      <td>[EvalResult(task_type='text-generation', datas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['Qwen2ForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'qwen2', 'text...</td>\n",
       "      <td>language:\\n- en\\nlicense: mit\\nlibrary_name: t...</td>\n",
       "      <td>77965463552</td>\n",
       "      <td>0.007802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Orenguteng/Llama-3.1-8B-Lexi-Uncensored-V2</td>\n",
       "      <td>Orenguteng/Llama-3.1-8B-Lexi-Uncensored-V2</td>\n",
       "      <td>2024-08-09 20:39:15+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>29053</td>\n",
       "      <td>87</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 8030261248...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[EvalResult(task_type='text-generation', datas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['LlamaForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'llama', 'text...</td>\n",
       "      <td>license: llama3.1\\nlibrary_name: transformers\\...</td>\n",
       "      <td>8030261248</td>\n",
       "      <td>0.020664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         model  \\\n",
       "18         ibm-granite/granite-3.0-8b-instruct   \n",
       "40                   arcee-ai/SuperNova-Medius   \n",
       "46                            bigscience/bloom   \n",
       "64              dfurman/CalmeRys-78B-Orpo-v0.1   \n",
       "72  Orenguteng/Llama-3.1-8B-Lexi-Uncensored-V2   \n",
       "\n",
       "                                            id                 created_at  \\\n",
       "18         ibm-granite/granite-3.0-8b-instruct  2024-10-02 21:16:23+00:00   \n",
       "40                   arcee-ai/SuperNova-Medius  2024-10-02 06:50:01+00:00   \n",
       "46                            bigscience/bloom  2022-05-19 11:53:33+00:00   \n",
       "64              dfurman/CalmeRys-78B-Orpo-v0.1  2024-09-24 10:25:46+00:00   \n",
       "72  Orenguteng/Llama-3.1-8B-Lexi-Uncensored-V2  2024-08-09 20:39:15+00:00   \n",
       "\n",
       "   downloads_all_time  downloads  likes  \\\n",
       "18            Unknown      19349    148   \n",
       "40            Unknown       7777    160   \n",
       "46            Unknown      10666   4760   \n",
       "64            Unknown       5470     35   \n",
       "72            Unknown      29053     87   \n",
       "\n",
       "                                          safetensors             task  \\\n",
       "18  SafeTensorsInfo(parameters={'BF16': 8170848256...  text-generation   \n",
       "40  SafeTensorsInfo(parameters={'BF16': 1477003366...  text-generation   \n",
       "46  SafeTensorsInfo(parameters={'BF16': 1762472714...  text-generation   \n",
       "64  SafeTensorsInfo(parameters={'BF16': 7796546355...  text-generation   \n",
       "72  SafeTensorsInfo(parameters={'BF16': 8030261248...  text-generation   \n",
       "\n",
       "                         datasets  \\\n",
       "18                            NaN   \n",
       "40                            NaN   \n",
       "46                            NaN   \n",
       "64  ['mlabonne/orpo-dpo-mix-40k']   \n",
       "72                            NaN   \n",
       "\n",
       "                                         eval_results metrics  library_name  \\\n",
       "18  [EvalResult(task_type='text-generation', datas...     NaN  transformers   \n",
       "40  [EvalResult(task_type='text-generation', datas...     NaN  transformers   \n",
       "46  [EvalResult(task_type='text-generation', datas...     NaN  transformers   \n",
       "64  [EvalResult(task_type='text-generation', datas...     NaN  transformers   \n",
       "72  [EvalResult(task_type='text-generation', datas...     NaN  transformers   \n",
       "\n",
       "                                    transformers_info            architecture  \\\n",
       "18  TransformersInfo(auto_model='AutoModelForCausa...  ['GraniteForCausalLM']   \n",
       "40  TransformersInfo(auto_model='AutoModelForCausa...    ['Qwen2ForCausalLM']   \n",
       "46  TransformersInfo(auto_model='AutoModelForCausa...    ['BloomForCausalLM']   \n",
       "64  TransformersInfo(auto_model='AutoModelForCausa...    ['Qwen2ForCausalLM']   \n",
       "72  TransformersInfo(auto_model='AutoModelForCausa...    ['LlamaForCausalLM']   \n",
       "\n",
       "                                                 tags  \\\n",
       "18  ['transformers', 'safetensors', 'granite', 'te...   \n",
       "40  ['transformers', 'safetensors', 'qwen2', 'text...   \n",
       "46  ['transformers', 'pytorch', 'tensorboard', 'sa...   \n",
       "64  ['transformers', 'safetensors', 'qwen2', 'text...   \n",
       "72  ['transformers', 'safetensors', 'llama', 'text...   \n",
       "\n",
       "                                            card_data  num_parameters  \\\n",
       "18  license: apache-2.0\\nlibrary_name: transformer...      8170848256   \n",
       "40  license: apache-2.0\\nlibrary_name: transformer...     14770033664   \n",
       "46  language:\\n- ak\\n- ar\\n- as\\n- bm\\n- bn\\n- ca\\...    176247271424   \n",
       "64  language:\\n- en\\nlicense: mit\\nlibrary_name: t...     77965463552   \n",
       "72  license: llama3.1\\nlibrary_name: transformers\\...      8030261248   \n",
       "\n",
       "    popularity  \n",
       "18    0.032682  \n",
       "40    0.034252  \n",
       "46    1.000876  \n",
       "64    0.007802  \n",
       "72    0.020664  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding popularity column: sum of normalized likes and downloads\n",
    "\n",
    "# Normalize the 'likes' and 'downloads' columns\n",
    "#filtered_df['normalized_likes'] = df['likes'] / df['likes'].max()\n",
    "#df['normalized_downloads'] = df['downloads'] / df['downloads'].max()\n",
    "\n",
    "# Calculate the sum of the normalized 'likes' and 'downloads'\n",
    "print(f\"likes max: {filtered_df['likes'].max()} downloads max: {filtered_df['downloads'].max()}\")\n",
    "filtered_df['popularity'] = (filtered_df['likes'] / filtered_df['likes'].max()) + (filtered_df['downloads'] / filtered_df['downloads'].max())\n",
    "print(f\"popularity max: {filtered_df['popularity'].max()} \")\n",
    "\n",
    "\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['created_at'] = pd.to_datetime(filtered_df['created_at'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering all models without date filter\n"
     ]
    }
   ],
   "source": [
    "# If filter by any date\n",
    "\n",
    "filter_date = False\n",
    "if filter_date :\n",
    "    # Filter models with 'created_at' in 2023 or later\n",
    "    year = 2021\n",
    "    filtered_df = filtered_df[filtered_df['created_at'].dt.year >= year]\n",
    "\n",
    "    print(f\"filtered w/ created_at len now:{len(filtered_df)}\")\n",
    "else:\n",
    "    print(\"Considering all models without date filter\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1933\n",
      "limit of num_parameters considered: 5000000000.0\n",
      "597\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>downloads_all_time</th>\n",
       "      <th>downloads</th>\n",
       "      <th>likes</th>\n",
       "      <th>safetensors</th>\n",
       "      <th>task</th>\n",
       "      <th>datasets</th>\n",
       "      <th>eval_results</th>\n",
       "      <th>metrics</th>\n",
       "      <th>library_name</th>\n",
       "      <th>transformers_info</th>\n",
       "      <th>architecture</th>\n",
       "      <th>tags</th>\n",
       "      <th>card_data</th>\n",
       "      <th>num_parameters</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>ibm-granite/granite-3.0-2b-instruct</td>\n",
       "      <td>ibm-granite/granite-3.0-2b-instruct</td>\n",
       "      <td>2024-10-02 21:07:46+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>11284</td>\n",
       "      <td>31</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 2634201088...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[EvalResult(task_type='text-generation', datas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['GraniteForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'granite', 'te...</td>\n",
       "      <td>license: apache-2.0\\nlibrary_name: transformer...</td>\n",
       "      <td>2634201088</td>\n",
       "      <td>0.007439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Lyte/Llama-3.2-3B-Overthinker</td>\n",
       "      <td>Lyte/Llama-3.2-3B-Overthinker</td>\n",
       "      <td>2024-10-17 22:49:53+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>717</td>\n",
       "      <td>18</td>\n",
       "      <td>SafeTensorsInfo(parameters={'F16': 3212749824}...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>['Lyte/Reasoning-Paused']</td>\n",
       "      <td>[EvalResult(task_type='text-generation', datas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['LlamaForCausalLM']</td>\n",
       "      <td>['transformers', 'pytorch', 'safetensors', 'll...</td>\n",
       "      <td>language:\\n- en\\nlicense: apache-2.0\\ntags:\\n-...</td>\n",
       "      <td>3212749824</td>\n",
       "      <td>0.003840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>distilbert/distilgpt2</td>\n",
       "      <td>distilbert/distilgpt2</td>\n",
       "      <td>2022-03-02 23:29:04+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>3973493</td>\n",
       "      <td>442</td>\n",
       "      <td>SafeTensorsInfo(parameters={'F32': 88204032}, ...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>['openwebtext']</td>\n",
       "      <td>[EvalResult(task_type='text-generation', datas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['GPT2LMHeadModel']</td>\n",
       "      <td>['transformers', 'pytorch', 'tf', 'jax', 'tfli...</td>\n",
       "      <td>language: en\\nlicense: apache-2.0\\ntags:\\n- ex...</td>\n",
       "      <td>88204032</td>\n",
       "      <td>0.419247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>bigcode/starcoder2-3b</td>\n",
       "      <td>bigcode/starcoder2-3b</td>\n",
       "      <td>2023-11-29 15:22:51+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>161709</td>\n",
       "      <td>146</td>\n",
       "      <td>SafeTensorsInfo(parameters={'F32': 3030371328}...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>['bigcode/the-stack-v2-train']</td>\n",
       "      <td>[EvalResult(task_type='text-generation', datas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['Starcoder2ForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'starcoder2', ...</td>\n",
       "      <td>license: bigcode-openrail-m\\nlibrary_name: tra...</td>\n",
       "      <td>3030371328</td>\n",
       "      <td>0.043955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>facebook/layerskip-llama3.2-1B</td>\n",
       "      <td>facebook/layerskip-llama3.2-1B</td>\n",
       "      <td>2024-10-17 10:05:32+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>471</td>\n",
       "      <td>15</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 1235814400...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[EvalResult(task_type='question-answering', da...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['LlamaForCausalLM']</td>\n",
       "      <td>['transformers', 'pytorch', 'safetensors', 'll...</td>\n",
       "      <td>language:\\n- en\\nlicense: other\\nlibrary_name:...</td>\n",
       "      <td>1235814400</td>\n",
       "      <td>0.003190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   model                                   id  \\\n",
       "89   ibm-granite/granite-3.0-2b-instruct  ibm-granite/granite-3.0-2b-instruct   \n",
       "90         Lyte/Llama-3.2-3B-Overthinker        Lyte/Llama-3.2-3B-Overthinker   \n",
       "178                distilbert/distilgpt2                distilbert/distilgpt2   \n",
       "197                bigcode/starcoder2-3b                bigcode/starcoder2-3b   \n",
       "313       facebook/layerskip-llama3.2-1B       facebook/layerskip-llama3.2-1B   \n",
       "\n",
       "                   created_at downloads_all_time  downloads  likes  \\\n",
       "89  2024-10-02 21:07:46+00:00            Unknown      11284     31   \n",
       "90  2024-10-17 22:49:53+00:00            Unknown        717     18   \n",
       "178 2022-03-02 23:29:04+00:00            Unknown    3973493    442   \n",
       "197 2023-11-29 15:22:51+00:00            Unknown     161709    146   \n",
       "313 2024-10-17 10:05:32+00:00            Unknown        471     15   \n",
       "\n",
       "                                           safetensors             task  \\\n",
       "89   SafeTensorsInfo(parameters={'BF16': 2634201088...  text-generation   \n",
       "90   SafeTensorsInfo(parameters={'F16': 3212749824}...  text-generation   \n",
       "178  SafeTensorsInfo(parameters={'F32': 88204032}, ...  text-generation   \n",
       "197  SafeTensorsInfo(parameters={'F32': 3030371328}...  text-generation   \n",
       "313  SafeTensorsInfo(parameters={'BF16': 1235814400...  text-generation   \n",
       "\n",
       "                           datasets  \\\n",
       "89                              NaN   \n",
       "90        ['Lyte/Reasoning-Paused']   \n",
       "178                 ['openwebtext']   \n",
       "197  ['bigcode/the-stack-v2-train']   \n",
       "313                             NaN   \n",
       "\n",
       "                                          eval_results metrics  library_name  \\\n",
       "89   [EvalResult(task_type='text-generation', datas...     NaN  transformers   \n",
       "90   [EvalResult(task_type='text-generation', datas...     NaN  transformers   \n",
       "178  [EvalResult(task_type='text-generation', datas...     NaN  transformers   \n",
       "197  [EvalResult(task_type='text-generation', datas...     NaN  transformers   \n",
       "313  [EvalResult(task_type='question-answering', da...     NaN  transformers   \n",
       "\n",
       "                                     transformers_info  \\\n",
       "89   TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "90   TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "178  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "197  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "313  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "\n",
       "                  architecture  \\\n",
       "89      ['GraniteForCausalLM']   \n",
       "90        ['LlamaForCausalLM']   \n",
       "178        ['GPT2LMHeadModel']   \n",
       "197  ['Starcoder2ForCausalLM']   \n",
       "313       ['LlamaForCausalLM']   \n",
       "\n",
       "                                                  tags  \\\n",
       "89   ['transformers', 'safetensors', 'granite', 'te...   \n",
       "90   ['transformers', 'pytorch', 'safetensors', 'll...   \n",
       "178  ['transformers', 'pytorch', 'tf', 'jax', 'tfli...   \n",
       "197  ['transformers', 'safetensors', 'starcoder2', ...   \n",
       "313  ['transformers', 'pytorch', 'safetensors', 'll...   \n",
       "\n",
       "                                             card_data  num_parameters  \\\n",
       "89   license: apache-2.0\\nlibrary_name: transformer...      2634201088   \n",
       "90   language:\\n- en\\nlicense: apache-2.0\\ntags:\\n-...      3212749824   \n",
       "178  language: en\\nlicense: apache-2.0\\ntags:\\n- ex...        88204032   \n",
       "197  license: bigcode-openrail-m\\nlibrary_name: tra...      3030371328   \n",
       "313  language:\\n- en\\nlicense: other\\nlibrary_name:...      1235814400   \n",
       "\n",
       "     popularity  \n",
       "89     0.007439  \n",
       "90     0.003840  \n",
       "178    0.419247  \n",
       "197    0.043955  \n",
       "313    0.003190  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out rows where the 'safetensors' column is NaN\n",
    "limit_slm_parameters=5 *1e9 # 10B\n",
    "print(len(filtered_df))\n",
    "print(f'limit of num_parameters considered: {limit_slm_parameters}')\n",
    "filtered_df = filtered_df[filtered_df['num_parameters'] <= limit_slm_parameters]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(len(filtered_df))\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered DataFrame Length: 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>downloads_all_time</th>\n",
       "      <th>downloads</th>\n",
       "      <th>likes</th>\n",
       "      <th>safetensors</th>\n",
       "      <th>task</th>\n",
       "      <th>datasets</th>\n",
       "      <th>eval_results</th>\n",
       "      <th>metrics</th>\n",
       "      <th>library_name</th>\n",
       "      <th>transformers_info</th>\n",
       "      <th>architecture</th>\n",
       "      <th>tags</th>\n",
       "      <th>card_data</th>\n",
       "      <th>num_parameters</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>bigcode/starcoder2-3b</td>\n",
       "      <td>bigcode/starcoder2-3b</td>\n",
       "      <td>2023-11-29 15:22:51+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>161709</td>\n",
       "      <td>146</td>\n",
       "      <td>SafeTensorsInfo(parameters={'F32': 3030371328}...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>['bigcode/the-stack-v2-train']</td>\n",
       "      <td>[EvalResult(task_type='text-generation', datas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['Starcoder2ForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'starcoder2', ...</td>\n",
       "      <td>license: bigcode-openrail-m\\nlibrary_name: tra...</td>\n",
       "      <td>3030371328</td>\n",
       "      <td>0.043955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>facebook/layerskip-llama3.2-1B</td>\n",
       "      <td>facebook/layerskip-llama3.2-1B</td>\n",
       "      <td>2024-10-17 10:05:32+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>471</td>\n",
       "      <td>15</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 1235814400...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[EvalResult(task_type='question-answering', da...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['LlamaForCausalLM']</td>\n",
       "      <td>['transformers', 'pytorch', 'safetensors', 'll...</td>\n",
       "      <td>language:\\n- en\\nlicense: other\\nlibrary_name:...</td>\n",
       "      <td>1235814400</td>\n",
       "      <td>0.003190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>bigscience/bloomz-560m</td>\n",
       "      <td>bigscience/bloomz-560m</td>\n",
       "      <td>2022-10-08 16:14:42+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>12174074</td>\n",
       "      <td>105</td>\n",
       "      <td>SafeTensorsInfo(parameters={'F16': 559214592},...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>['bigscience/xP3']</td>\n",
       "      <td>[EvalResult(task_type='Coreference resolution'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['BloomForCausalLM']</td>\n",
       "      <td>['transformers', 'pytorch', 'tensorboard', 'sa...</td>\n",
       "      <td>language:\\n- ak\\n- ar\\n- as\\n- bm\\n- bn\\n- ca\\...</td>\n",
       "      <td>559214592</td>\n",
       "      <td>1.022059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>bigscience/bloomz-1b1</td>\n",
       "      <td>bigscience/bloomz-1b1</td>\n",
       "      <td>2022-10-08 16:16:01+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>3627</td>\n",
       "      <td>32</td>\n",
       "      <td>SafeTensorsInfo(parameters={'F16': 1065314304}...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>['bigscience/xP3']</td>\n",
       "      <td>[EvalResult(task_type='Coreference resolution'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['BloomForCausalLM']</td>\n",
       "      <td>['transformers', 'pytorch', 'tensorboard', 'sa...</td>\n",
       "      <td>language:\\n- ak\\n- ar\\n- as\\n- bm\\n- bn\\n- ca\\...</td>\n",
       "      <td>1065314304</td>\n",
       "      <td>0.007021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>bigcode/starcoderbase-1b</td>\n",
       "      <td>bigcode/starcoderbase-1b</td>\n",
       "      <td>2023-07-03 13:08:44+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>7287</td>\n",
       "      <td>64</td>\n",
       "      <td>SafeTensorsInfo(parameters={'F32': 1137207296}...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>['bigcode/the-stack-dedup']</td>\n",
       "      <td>[EvalResult(task_type='text-generation', datas...</td>\n",
       "      <td>['code_eval']</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['GPTBigCodeForCausalLM']</td>\n",
       "      <td>['transformers', 'pytorch', 'safetensors', 'gp...</td>\n",
       "      <td>license: bigcode-openrail-m\\nlibrary_name: tra...</td>\n",
       "      <td>1137207296</td>\n",
       "      <td>0.014044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              model                              id  \\\n",
       "197           bigcode/starcoder2-3b           bigcode/starcoder2-3b   \n",
       "313  facebook/layerskip-llama3.2-1B  facebook/layerskip-llama3.2-1B   \n",
       "443          bigscience/bloomz-560m          bigscience/bloomz-560m   \n",
       "444           bigscience/bloomz-1b1           bigscience/bloomz-1b1   \n",
       "565        bigcode/starcoderbase-1b        bigcode/starcoderbase-1b   \n",
       "\n",
       "                   created_at downloads_all_time  downloads  likes  \\\n",
       "197 2023-11-29 15:22:51+00:00            Unknown     161709    146   \n",
       "313 2024-10-17 10:05:32+00:00            Unknown        471     15   \n",
       "443 2022-10-08 16:14:42+00:00            Unknown   12174074    105   \n",
       "444 2022-10-08 16:16:01+00:00            Unknown       3627     32   \n",
       "565 2023-07-03 13:08:44+00:00            Unknown       7287     64   \n",
       "\n",
       "                                           safetensors             task  \\\n",
       "197  SafeTensorsInfo(parameters={'F32': 3030371328}...  text-generation   \n",
       "313  SafeTensorsInfo(parameters={'BF16': 1235814400...  text-generation   \n",
       "443  SafeTensorsInfo(parameters={'F16': 559214592},...  text-generation   \n",
       "444  SafeTensorsInfo(parameters={'F16': 1065314304}...  text-generation   \n",
       "565  SafeTensorsInfo(parameters={'F32': 1137207296}...  text-generation   \n",
       "\n",
       "                           datasets  \\\n",
       "197  ['bigcode/the-stack-v2-train']   \n",
       "313                             NaN   \n",
       "443              ['bigscience/xP3']   \n",
       "444              ['bigscience/xP3']   \n",
       "565     ['bigcode/the-stack-dedup']   \n",
       "\n",
       "                                          eval_results        metrics  \\\n",
       "197  [EvalResult(task_type='text-generation', datas...            NaN   \n",
       "313  [EvalResult(task_type='question-answering', da...            NaN   \n",
       "443  [EvalResult(task_type='Coreference resolution'...            NaN   \n",
       "444  [EvalResult(task_type='Coreference resolution'...            NaN   \n",
       "565  [EvalResult(task_type='text-generation', datas...  ['code_eval']   \n",
       "\n",
       "     library_name                                  transformers_info  \\\n",
       "197  transformers  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "313  transformers  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "443  transformers  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "444  transformers  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "565  transformers  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "\n",
       "                  architecture  \\\n",
       "197  ['Starcoder2ForCausalLM']   \n",
       "313       ['LlamaForCausalLM']   \n",
       "443       ['BloomForCausalLM']   \n",
       "444       ['BloomForCausalLM']   \n",
       "565  ['GPTBigCodeForCausalLM']   \n",
       "\n",
       "                                                  tags  \\\n",
       "197  ['transformers', 'safetensors', 'starcoder2', ...   \n",
       "313  ['transformers', 'pytorch', 'safetensors', 'll...   \n",
       "443  ['transformers', 'pytorch', 'tensorboard', 'sa...   \n",
       "444  ['transformers', 'pytorch', 'tensorboard', 'sa...   \n",
       "565  ['transformers', 'pytorch', 'safetensors', 'gp...   \n",
       "\n",
       "                                             card_data  num_parameters  \\\n",
       "197  license: bigcode-openrail-m\\nlibrary_name: tra...      3030371328   \n",
       "313  language:\\n- en\\nlicense: other\\nlibrary_name:...      1235814400   \n",
       "443  language:\\n- ak\\n- ar\\n- as\\n- bm\\n- bn\\n- ca\\...       559214592   \n",
       "444  language:\\n- ak\\n- ar\\n- as\\n- bm\\n- bn\\n- ca\\...      1065314304   \n",
       "565  license: bigcode-openrail-m\\nlibrary_name: tra...      1137207296   \n",
       "\n",
       "     popularity  \n",
       "197    0.043955  \n",
       "313    0.003190  \n",
       "443    1.022059  \n",
       "444    0.007021  \n",
       "565    0.014044  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Define a regex pattern to match 'dataset_name' containing 'humaneval' (case insensitive)\n",
    "pattern = r\"dataset_name=['\\\"]humaneval['\\\"]\" # there are other like 'humanevalsynthesis'\n",
    "\n",
    "# Filter rows where 'eval_results' matches the regex pattern\n",
    "filtered_df = filtered_df[\n",
    "    filtered_df['eval_results'].str.contains(pattern, case=False, na=False)\n",
    "]\n",
    "\n",
    "# Display the length of the filtered DataFrame\n",
    "print(\"Filtered DataFrame Length:\", len(filtered_df))\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_filtered_df =False\n",
    "if save_filtered_df:\n",
    "    # Optional: Save the filtered DataFrame to a CSV file\n",
    "    filtered_df.to_csv(save_dir + \"filtered_models.csv\", index=False)\n",
    "    print(f\"Filtered CSV file saved: {save_dir}filtered_models.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model                       TheBloke/Phind-CodeLlama-34B-Python-v1-GPTQ\n",
       "id                          TheBloke/Phind-CodeLlama-34B-Python-v1-GPTQ\n",
       "created_at                                    2023-08-26 13:39:11+00:00\n",
       "downloads_all_time                                              Unknown\n",
       "downloads                                                            43\n",
       "likes                                                                 7\n",
       "safetensors           SafeTensorsInfo(parameters={'I32': 4156200960,...\n",
       "task                                                    text-generation\n",
       "datasets                                                            NaN\n",
       "eval_results          [EvalResult(task_type='text-generation', datas...\n",
       "metrics                                                             NaN\n",
       "library_name                                               transformers\n",
       "transformers_info     TransformersInfo(auto_model='AutoModelForCausa...\n",
       "architecture                                       ['LlamaForCausalLM']\n",
       "tags                  ['transformers', 'safetensors', 'llama', 'text...\n",
       "card_data             license: llama2\\ntags:\\n- code llama\\nbase_mod...\n",
       "num_parameters                                               4688066560\n",
       "popularity                                                     0.001474\n",
       "Name: 16979, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "import random\n",
    "i = random.randint(0,len(filtered_df))\n",
    "print(i)\n",
    "row = filtered_df.iloc[i]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stratified sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total models: 69\n"
     ]
    }
   ],
   "source": [
    "save_dir = 'model_selection/results/'\n",
    "file_name = save_dir+'filtered_models.csv'\n",
    "df = pd.read_csv(file_name)\n",
    "print(f'total models: {len(df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['model', 'id', 'created_at', 'downloads_all_time', 'downloads', 'likes',\n",
       "       'safetensors', 'task', 'datasets', 'eval_results', 'metrics',\n",
       "       'library_name', 'transformers_info', 'architecture', 'tags',\n",
       "       'card_data', 'num_parameters', 'popularity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add likes: popularity = sum of the normalized likes and downloads\n",
    "stratification_criteria = ['popularity', 'num_parameters','created_at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   popularity_quartile  created_at_quartile  num_parameters_quartile\n",
      "0                    1                    1                        1\n",
      "1                    1                    1                        1\n",
      "2                    1                    0                        0\n",
      "3                    1                    0                        0\n",
      "4                    1                    0                        0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have loaded your DataFrame 'df'\n",
    "\n",
    "# Convert 'created_at' to a numerical format for quartile calculation\n",
    "df['created_at'] = pd.to_datetime(df['created_at'], errors='coerce')\n",
    "df['created_at_numeric'] = df['created_at'].astype(int) // 10**9  # Convert to Unix timestamp, seconds\n",
    "\n",
    "# Create quartiles for stratified sampling\n",
    "df['popularity_quartile'] = pd.qcut(df['popularity'], q=2, labels=False)  # 2 quartiles\n",
    "df['created_at_quartile'] = pd.qcut(df['created_at_numeric'], q=2, labels=False)  # 2 quartiles\n",
    "df['num_parameters_quartile'] = pd.qcut(df['num_parameters'], q=3, labels=False)  # 3 quartiles\n",
    "\n",
    "# Display the DataFrame with new quartile columns\n",
    "print(df[['popularity_quartile', 'created_at_quartile', 'num_parameters_quartile']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered CSV file saved: model_selection/results/selected_models.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_169904/1651244523.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  selected_models = strata.apply(lambda x: x.sample(1)).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>downloads_all_time</th>\n",
       "      <th>downloads</th>\n",
       "      <th>likes</th>\n",
       "      <th>safetensors</th>\n",
       "      <th>task</th>\n",
       "      <th>datasets</th>\n",
       "      <th>eval_results</th>\n",
       "      <th>...</th>\n",
       "      <th>transformers_info</th>\n",
       "      <th>architecture</th>\n",
       "      <th>tags</th>\n",
       "      <th>card_data</th>\n",
       "      <th>num_parameters</th>\n",
       "      <th>popularity</th>\n",
       "      <th>created_at_numeric</th>\n",
       "      <th>popularity_quartile</th>\n",
       "      <th>created_at_quartile</th>\n",
       "      <th>num_parameters_quartile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TheBloke/speechless-code-mistral-7B-v1.0-GPTQ</td>\n",
       "      <td>TheBloke/speechless-code-mistral-7B-v1.0-GPTQ</td>\n",
       "      <td>2023-10-13 06:08:01+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>SafeTensorsInfo(parameters={'I32': 880476160, ...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>['jondurbin/airoboros-2.2', 'Open-Orca/OpenOrc...</td>\n",
       "      <td>[EvalResult(task_type='text-generation', datas...</td>\n",
       "      <td>...</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['MistralForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'mistral', 'te...</td>\n",
       "      <td>language:\\n- en\\nlicense: llama2\\nlibrary_name...</td>\n",
       "      <td>1198788608</td>\n",
       "      <td>6.558938e-03</td>\n",
       "      <td>1697177281</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TheBloke/WizardCoder-Python-13B-V1.0-AWQ</td>\n",
       "      <td>TheBloke/WizardCoder-Python-13B-V1.0-AWQ</td>\n",
       "      <td>2023-09-19 00:53:10+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>SafeTensorsInfo(parameters={'I32': 1598361600,...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[EvalResult(task_type='text-generation', datas...</td>\n",
       "      <td>...</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['LlamaForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'llama', 'text...</td>\n",
       "      <td>license: llama2\\nlibrary_name: transformers\\nt...</td>\n",
       "      <td>2025589760</td>\n",
       "      <td>1.807119e-06</td>\n",
       "      <td>1695084790</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vodkaslime/test-repo-stablecode</td>\n",
       "      <td>vodkaslime/test-repo-stablecode</td>\n",
       "      <td>2023-08-23 07:50:01+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 2769311040...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[EvalResult(task_type='text-generation', datas...</td>\n",
       "      <td>...</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['GPTNeoXForCausalLM']</td>\n",
       "      <td>['transformers', 'pytorch', 'safetensors', 'gp...</td>\n",
       "      <td>language:\\n- code\\nlicense: other\\ntags:\\n- ca...</td>\n",
       "      <td>3306181952</td>\n",
       "      <td>2.710678e-06</td>\n",
       "      <td>1692777001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TechxGenus/starcoder2-3b-GPTQ</td>\n",
       "      <td>TechxGenus/starcoder2-3b-GPTQ</td>\n",
       "      <td>2024-03-22 13:35:25+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>945</td>\n",
       "      <td>1</td>\n",
       "      <td>SafeTensorsInfo(parameters={'I32': 363432960, ...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>['bigcode/the-stack-v2-train']</td>\n",
       "      <td>[EvalResult(task_type='text-generation', datas...</td>\n",
       "      <td>...</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['Starcoder2ForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'starcoder2', ...</td>\n",
       "      <td>license: bigcode-openrail-m\\nlibrary_name: tra...</td>\n",
       "      <td>688945152</td>\n",
       "      <td>3.356312e-03</td>\n",
       "      <td>1711114525</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TechxGenus/starcoder2-15b-AWQ</td>\n",
       "      <td>TechxGenus/starcoder2-15b-AWQ</td>\n",
       "      <td>2024-04-12 14:03:22+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>SafeTensorsInfo(parameters={'I32': 1933885440,...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>['bigcode/the-stack-v2-train']</td>\n",
       "      <td>[EvalResult(task_type='text-generation', datas...</td>\n",
       "      <td>...</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['Starcoder2ForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'starcoder2', ...</td>\n",
       "      <td>license: bigcode-openrail-m\\nlibrary_name: tra...</td>\n",
       "      <td>2661535744</td>\n",
       "      <td>3.280988e-03</td>\n",
       "      <td>1712930602</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nlpguy/granite-3.0-3b-a800m-base</td>\n",
       "      <td>nlpguy/granite-3.0-3b-a800m-base</td>\n",
       "      <td>2024-10-31 14:29:25+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>SafeTensorsInfo(parameters={'F32': 3374286336}...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[EvalResult(task_type='text-generation', datas...</td>\n",
       "      <td>...</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['GraniteMoeForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'granitemoe', ...</td>\n",
       "      <td>license: apache-2.0\\nlibrary_name: transformer...</td>\n",
       "      <td>3374286336</td>\n",
       "      <td>4.107089e-07</td>\n",
       "      <td>1730384965</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TheBloke/WizardCoder-Python-7B-V1.0-AWQ</td>\n",
       "      <td>TheBloke/WizardCoder-Python-7B-V1.0-AWQ</td>\n",
       "      <td>2023-09-19 00:52:16+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>118</td>\n",
       "      <td>2</td>\n",
       "      <td>SafeTensorsInfo(parameters={'I32': 815824896, ...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[EvalResult(task_type='text-generation', datas...</td>\n",
       "      <td>...</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['LlamaForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'llama', 'text...</td>\n",
       "      <td>license: llama2\\nlibrary_name: transformers\\nt...</td>\n",
       "      <td>1128837120</td>\n",
       "      <td>6.567070e-03</td>\n",
       "      <td>1695084736</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>smallcloudai/Refact-1_6B-fim</td>\n",
       "      <td>smallcloudai/Refact-1_6B-fim</td>\n",
       "      <td>2023-08-29 15:48:36+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>28033</td>\n",
       "      <td>129</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 1585842176...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>['bigcode/the-stack-dedup', 'rombodawg/2XUNCEN...</td>\n",
       "      <td>[EvalResult(task_type='text-generation', datas...</td>\n",
       "      <td>...</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['GPTRefactForCausalLM']</td>\n",
       "      <td>['transformers', 'pytorch', 'safetensors', 'gp...</td>\n",
       "      <td>language:\\n- en\\nlicense: bigscience-openrail-...</td>\n",
       "      <td>1585842176</td>\n",
       "      <td>4.252535e-01</td>\n",
       "      <td>1693324116</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>stabilityai/stablecode-completion-alpha-3b-4k</td>\n",
       "      <td>stabilityai/stablecode-completion-alpha-3b-4k</td>\n",
       "      <td>2023-08-07 16:59:19+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1657</td>\n",
       "      <td>284</td>\n",
       "      <td>SafeTensorsInfo(parameters={'F16': 2769311040,...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>['bigcode/starcoderdata']</td>\n",
       "      <td>[EvalResult(task_type='text-generation', datas...</td>\n",
       "      <td>...</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['GPTNeoXForCausalLM']</td>\n",
       "      <td>['transformers', 'pytorch', 'safetensors', 'gp...</td>\n",
       "      <td>language:\\n- code\\nlicense: apache-2.0\\ntags:\\...</td>\n",
       "      <td>3306181952</td>\n",
       "      <td>9.312836e-01</td>\n",
       "      <td>1691427559</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ibm-granite/granite-3.0-1b-a400m-base</td>\n",
       "      <td>ibm-granite/granite-3.0-1b-a400m-base</td>\n",
       "      <td>2024-10-03 21:58:13+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2337</td>\n",
       "      <td>5</td>\n",
       "      <td>SafeTensorsInfo(parameters={'F32': 1384956928}...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[EvalResult(task_type='text-generation', datas...</td>\n",
       "      <td>...</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['GraniteMoeForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'granitemoe', ...</td>\n",
       "      <td>license: apache-2.0\\nlibrary_name: transformer...</td>\n",
       "      <td>1384956928</td>\n",
       "      <td>1.658541e-02</td>\n",
       "      <td>1727992693</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TheBloke/WizardCoder-33B-V1.1-GPTQ</td>\n",
       "      <td>TheBloke/WizardCoder-33B-V1.1-GPTQ</td>\n",
       "      <td>2024-01-04 17:19:01+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>SafeTensorsInfo(parameters={'I32': 4114296192,...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[EvalResult(task_type='text-generation', datas...</td>\n",
       "      <td>...</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['LlamaForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'llama', 'text...</td>\n",
       "      <td>library_name: transformers\\ntags:\\n- code\\nbas...</td>\n",
       "      <td>4585296256</td>\n",
       "      <td>3.606755e-02</td>\n",
       "      <td>1704388741</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            model  \\\n",
       "0   TheBloke/speechless-code-mistral-7B-v1.0-GPTQ   \n",
       "1        TheBloke/WizardCoder-Python-13B-V1.0-AWQ   \n",
       "2                 vodkaslime/test-repo-stablecode   \n",
       "3                   TechxGenus/starcoder2-3b-GPTQ   \n",
       "4                   TechxGenus/starcoder2-15b-AWQ   \n",
       "5                nlpguy/granite-3.0-3b-a800m-base   \n",
       "6         TheBloke/WizardCoder-Python-7B-V1.0-AWQ   \n",
       "7                    smallcloudai/Refact-1_6B-fim   \n",
       "8   stabilityai/stablecode-completion-alpha-3b-4k   \n",
       "9           ibm-granite/granite-3.0-1b-a400m-base   \n",
       "10             TheBloke/WizardCoder-33B-V1.1-GPTQ   \n",
       "\n",
       "                                               id                created_at  \\\n",
       "0   TheBloke/speechless-code-mistral-7B-v1.0-GPTQ 2023-10-13 06:08:01+00:00   \n",
       "1        TheBloke/WizardCoder-Python-13B-V1.0-AWQ 2023-09-19 00:53:10+00:00   \n",
       "2                 vodkaslime/test-repo-stablecode 2023-08-23 07:50:01+00:00   \n",
       "3                   TechxGenus/starcoder2-3b-GPTQ 2024-03-22 13:35:25+00:00   \n",
       "4                   TechxGenus/starcoder2-15b-AWQ 2024-04-12 14:03:22+00:00   \n",
       "5                nlpguy/granite-3.0-3b-a800m-base 2024-10-31 14:29:25+00:00   \n",
       "6         TheBloke/WizardCoder-Python-7B-V1.0-AWQ 2023-09-19 00:52:16+00:00   \n",
       "7                    smallcloudai/Refact-1_6B-fim 2023-08-29 15:48:36+00:00   \n",
       "8   stabilityai/stablecode-completion-alpha-3b-4k 2023-08-07 16:59:19+00:00   \n",
       "9           ibm-granite/granite-3.0-1b-a400m-base 2024-10-03 21:58:13+00:00   \n",
       "10             TheBloke/WizardCoder-33B-V1.1-GPTQ 2024-01-04 17:19:01+00:00   \n",
       "\n",
       "   downloads_all_time  downloads  likes  \\\n",
       "0             Unknown         19      2   \n",
       "1             Unknown         22      0   \n",
       "2             Unknown         33      0   \n",
       "3             Unknown        945      1   \n",
       "4             Unknown         28      1   \n",
       "5             Unknown          5      0   \n",
       "6             Unknown        118      2   \n",
       "7             Unknown      28033    129   \n",
       "8             Unknown       1657    284   \n",
       "9             Unknown       2337      5   \n",
       "10            Unknown         24     11   \n",
       "\n",
       "                                          safetensors             task  \\\n",
       "0   SafeTensorsInfo(parameters={'I32': 880476160, ...  text-generation   \n",
       "1   SafeTensorsInfo(parameters={'I32': 1598361600,...  text-generation   \n",
       "2   SafeTensorsInfo(parameters={'BF16': 2769311040...  text-generation   \n",
       "3   SafeTensorsInfo(parameters={'I32': 363432960, ...  text-generation   \n",
       "4   SafeTensorsInfo(parameters={'I32': 1933885440,...  text-generation   \n",
       "5   SafeTensorsInfo(parameters={'F32': 3374286336}...  text-generation   \n",
       "6   SafeTensorsInfo(parameters={'I32': 815824896, ...  text-generation   \n",
       "7   SafeTensorsInfo(parameters={'BF16': 1585842176...  text-generation   \n",
       "8   SafeTensorsInfo(parameters={'F16': 2769311040,...  text-generation   \n",
       "9   SafeTensorsInfo(parameters={'F32': 1384956928}...  text-generation   \n",
       "10  SafeTensorsInfo(parameters={'I32': 4114296192,...  text-generation   \n",
       "\n",
       "                                             datasets  \\\n",
       "0   ['jondurbin/airoboros-2.2', 'Open-Orca/OpenOrc...   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                      ['bigcode/the-stack-v2-train']   \n",
       "4                      ['bigcode/the-stack-v2-train']   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7   ['bigcode/the-stack-dedup', 'rombodawg/2XUNCEN...   \n",
       "8                           ['bigcode/starcoderdata']   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "\n",
       "                                         eval_results  ...  \\\n",
       "0   [EvalResult(task_type='text-generation', datas...  ...   \n",
       "1   [EvalResult(task_type='text-generation', datas...  ...   \n",
       "2   [EvalResult(task_type='text-generation', datas...  ...   \n",
       "3   [EvalResult(task_type='text-generation', datas...  ...   \n",
       "4   [EvalResult(task_type='text-generation', datas...  ...   \n",
       "5   [EvalResult(task_type='text-generation', datas...  ...   \n",
       "6   [EvalResult(task_type='text-generation', datas...  ...   \n",
       "7   [EvalResult(task_type='text-generation', datas...  ...   \n",
       "8   [EvalResult(task_type='text-generation', datas...  ...   \n",
       "9   [EvalResult(task_type='text-generation', datas...  ...   \n",
       "10  [EvalResult(task_type='text-generation', datas...  ...   \n",
       "\n",
       "                                    transformers_info  \\\n",
       "0   TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "1   TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "2   TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "3   TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "4   TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "5   TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "6   TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "7   TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "8   TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "9   TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "10  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "\n",
       "                 architecture  \\\n",
       "0      ['MistralForCausalLM']   \n",
       "1        ['LlamaForCausalLM']   \n",
       "2      ['GPTNeoXForCausalLM']   \n",
       "3   ['Starcoder2ForCausalLM']   \n",
       "4   ['Starcoder2ForCausalLM']   \n",
       "5   ['GraniteMoeForCausalLM']   \n",
       "6        ['LlamaForCausalLM']   \n",
       "7    ['GPTRefactForCausalLM']   \n",
       "8      ['GPTNeoXForCausalLM']   \n",
       "9   ['GraniteMoeForCausalLM']   \n",
       "10       ['LlamaForCausalLM']   \n",
       "\n",
       "                                                 tags  \\\n",
       "0   ['transformers', 'safetensors', 'mistral', 'te...   \n",
       "1   ['transformers', 'safetensors', 'llama', 'text...   \n",
       "2   ['transformers', 'pytorch', 'safetensors', 'gp...   \n",
       "3   ['transformers', 'safetensors', 'starcoder2', ...   \n",
       "4   ['transformers', 'safetensors', 'starcoder2', ...   \n",
       "5   ['transformers', 'safetensors', 'granitemoe', ...   \n",
       "6   ['transformers', 'safetensors', 'llama', 'text...   \n",
       "7   ['transformers', 'pytorch', 'safetensors', 'gp...   \n",
       "8   ['transformers', 'pytorch', 'safetensors', 'gp...   \n",
       "9   ['transformers', 'safetensors', 'granitemoe', ...   \n",
       "10  ['transformers', 'safetensors', 'llama', 'text...   \n",
       "\n",
       "                                            card_data num_parameters  \\\n",
       "0   language:\\n- en\\nlicense: llama2\\nlibrary_name...     1198788608   \n",
       "1   license: llama2\\nlibrary_name: transformers\\nt...     2025589760   \n",
       "2   language:\\n- code\\nlicense: other\\ntags:\\n- ca...     3306181952   \n",
       "3   license: bigcode-openrail-m\\nlibrary_name: tra...      688945152   \n",
       "4   license: bigcode-openrail-m\\nlibrary_name: tra...     2661535744   \n",
       "5   license: apache-2.0\\nlibrary_name: transformer...     3374286336   \n",
       "6   license: llama2\\nlibrary_name: transformers\\nt...     1128837120   \n",
       "7   language:\\n- en\\nlicense: bigscience-openrail-...     1585842176   \n",
       "8   language:\\n- code\\nlicense: apache-2.0\\ntags:\\...     3306181952   \n",
       "9   license: apache-2.0\\nlibrary_name: transformer...     1384956928   \n",
       "10  library_name: transformers\\ntags:\\n- code\\nbas...     4585296256   \n",
       "\n",
       "      popularity  created_at_numeric  popularity_quartile  \\\n",
       "0   6.558938e-03          1697177281                    0   \n",
       "1   1.807119e-06          1695084790                    0   \n",
       "2   2.710678e-06          1692777001                    0   \n",
       "3   3.356312e-03          1711114525                    0   \n",
       "4   3.280988e-03          1712930602                    0   \n",
       "5   4.107089e-07          1730384965                    0   \n",
       "6   6.567070e-03          1695084736                    1   \n",
       "7   4.252535e-01          1693324116                    1   \n",
       "8   9.312836e-01          1691427559                    1   \n",
       "9   1.658541e-02          1727992693                    1   \n",
       "10  3.606755e-02          1704388741                    1   \n",
       "\n",
       "    created_at_quartile  num_parameters_quartile  \n",
       "0                     0                        0  \n",
       "1                     0                        1  \n",
       "2                     0                        2  \n",
       "3                     1                        0  \n",
       "4                     1                        1  \n",
       "5                     1                        2  \n",
       "6                     0                        0  \n",
       "7                     0                        1  \n",
       "8                     0                        2  \n",
       "9                     1                        1  \n",
       "10                    1                        2  \n",
       "\n",
       "[11 rows x 22 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by the quartile columns to create strata\n",
    "strata = df.groupby(['popularity_quartile', 'created_at_quartile', 'num_parameters_quartile'])\n",
    "\n",
    "# Select one model from each stratum\n",
    "selected_models = strata.apply(lambda x: x.sample(1)).reset_index(drop=True)\n",
    "\n",
    "# Display the selected models\n",
    "\n",
    "save_selected_df =True \n",
    "\n",
    "if save_selected_df:\n",
    "    # Optional: Save the filtered DataFrame to a CSV file\n",
    "    selected_models.to_csv(save_dir + \"selected_models_01.csv\", index=False)\n",
    "    print(f\"Filtered CSV file saved: {save_dir}selected_models.csv\")\n",
    "    \n",
    "selected_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:  Series([], Name: id, dtype: object)\n",
      "popularity Quartile: Series([], Name: popularity_quartile, dtype: int64)\n",
      "Created At Quartile: Series([], Name: created_at_quartile, dtype: int64)\n",
      "Num Parameters Quartile: Series([], Name: num_parameters_quartile, dtype: int64)\n",
      "---------------------\n",
      "model:  Series([], Name: id, dtype: object)\n",
      "popularity Quartile: Series([], Name: popularity_quartile, dtype: int64)\n",
      "Created At Quartile: Series([], Name: created_at_quartile, dtype: int64)\n",
      "Num Parameters Quartile: Series([], Name: num_parameters_quartile, dtype: int64)\n",
      "---------------------\n",
      "model:  Series([], Name: id, dtype: object)\n",
      "popularity Quartile: Series([], Name: popularity_quartile, dtype: int64)\n",
      "Created At Quartile: Series([], Name: created_at_quartile, dtype: int64)\n",
      "Num Parameters Quartile: Series([], Name: num_parameters_quartile, dtype: int64)\n",
      "---------------------\n",
      "model:  Series([], Name: id, dtype: object)\n",
      "popularity Quartile: Series([], Name: popularity_quartile, dtype: int64)\n",
      "Created At Quartile: Series([], Name: created_at_quartile, dtype: int64)\n",
      "Num Parameters Quartile: Series([], Name: num_parameters_quartile, dtype: int64)\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "used_models = [\"codeparrot/codeparrot-small\",\n",
    "               \"EleutherAI/pythia-410m\",\n",
    "               \"EleutherAI/pythia-1.4b\",\n",
    "               \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "               \"microsoft/phi-2\"\n",
    "               ]\n",
    "\n",
    "# Assuming 'df' is your DataFrame and you have a specific model ID\n",
    "model_id = used_models[1]  # Replace with the actual model ID\n",
    "\n",
    "for model_id in used_models[1:]: \n",
    "    # Filter the DataFrame to find the model with the given ID\n",
    "    model = df[df['id'] == model_id]\n",
    "    \n",
    "\n",
    "    # Get the quartile values for the selected model\n",
    "    popularity_quartile = model['popularity_quartile']\n",
    "    created_at_quartile = model['created_at_quartile']\n",
    "    num_parameters_quartile = model['num_parameters_quartile']\n",
    "\n",
    "    # Display the quartile values\n",
    "    print(\"model: \", model['id'])\n",
    "    print(\"popularity Quartile:\", popularity_quartile)\n",
    "    print(\"Created At Quartile:\", created_at_quartile)\n",
    "    print(\"Num Parameters Quartile:\", num_parameters_quartile)\n",
    "    print(\"---------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
