{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "1. Get metadata using script: extraction_slm.py, date of metadata extraction: 6/11/24\n",
    "2. This notebook to filter according to following criteria:\n",
    "  - humaneval\n",
    "  - num_parameters <5B\n",
    "  - has safetensors\n",
    "3. Obtained dataset with 403? possible models\n",
    "4. Check manually to those which need permission\n",
    "5. Obtain random models\n",
    "- Considering 1 per organization\n",
    "\n",
    "- Execute from \"Read file section\"\n",
    "- (optional) stratified sampling, if many models\n",
    "\n",
    "- Manual selection:\n",
    "  - discard any fine-tunning or quantized model, checked on model name and checked on model card\n",
    "  - discard those that do not have explicitly HumanEval (some we considered because they may have MultiHumanEval )\n",
    "###  first selection\n",
    "\n",
    "- text-generation []\n",
    "- decoder []\n",
    "\n",
    "- open-source models [x]\n",
    "- HF availability [x]\n",
    "- Task: text generation [x]\n",
    "- Date []\n",
    "- architecture: decoder-based only,  []\n",
    "- model size < SLMs size [x]\n",
    "  - https://huggingface.co/docs/accelerate/main/en/usage_guides/model_size_estimator?\n",
    "  - model size from endpoint?\n",
    "  - safetensors -> model_info.safetensors -> https://huggingface.co/microsoft/phi-2 [x]\n",
    "  - check it matches our data about models used []\n",
    "\n",
    "- [?]Code generation [] used in code generation, trained in code datasets?\n",
    "\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/fjdur/energy-ml-serving'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"model_selection/\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'model_selection/tmp/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read dataset from extraction_slm.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model(model_name, df):\n",
    "    return model_name in df['model'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total models: 104816\n"
     ]
    }
   ],
   "source": [
    "file_name = 'model_selection/results/decoder_models_info_02.csv'\n",
    "df = pd.read_csv(file_name)\n",
    "print(f'total models: {len(df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "check_model(\"microsoft/Phi-3-mini-128k-instruct\" ,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]['safetensors']\n",
    "df.iloc[0]['eval_results']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['model', 'id', 'created_at', 'downloads_all_time', 'downloads', 'likes',\n",
       "       'safetensors', 'task', 'datasets', 'eval_results', 'metrics',\n",
       "       'library_name', 'transformers_info', 'architecture', 'tags',\n",
       "       'card_data'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After safetensors check:  67761\n"
     ]
    }
   ],
   "source": [
    "# Filter out rows where the 'safetensors' column is NaN\n",
    "filtered_df = df[df['safetensors'].notna()]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(\"After safetensors check: \",len(filtered_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_180107/2495092620.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['num_parameters'] = filtered_df['safetensors'].apply(extract_total)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>downloads_all_time</th>\n",
       "      <th>downloads</th>\n",
       "      <th>likes</th>\n",
       "      <th>safetensors</th>\n",
       "      <th>task</th>\n",
       "      <th>datasets</th>\n",
       "      <th>eval_results</th>\n",
       "      <th>metrics</th>\n",
       "      <th>library_name</th>\n",
       "      <th>transformers_info</th>\n",
       "      <th>architecture</th>\n",
       "      <th>tags</th>\n",
       "      <th>card_data</th>\n",
       "      <th>num_parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HuggingFaceTB/SmolLM2-1.7B-Instruct</td>\n",
       "      <td>HuggingFaceTB/SmolLM2-1.7B-Instruct</td>\n",
       "      <td>2024-10-31 13:42:06+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>16940</td>\n",
       "      <td>233</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 1711376384...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['LlamaForCausalLM']</td>\n",
       "      <td>['transformers', 'tensorboard', 'onnx', 'safet...</td>\n",
       "      <td>language:\\n- en\\nlicense: apache-2.0\\nlibrary_...</td>\n",
       "      <td>1711376384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nvidia/Llama-3.1-Nemotron-70B-Instruct-HF</td>\n",
       "      <td>nvidia/Llama-3.1-Nemotron-70B-Instruct-HF</td>\n",
       "      <td>2024-10-12 02:37:13+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>186569</td>\n",
       "      <td>1495</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 7055370649...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>['nvidia/HelpSteer2']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['LlamaForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'llama', 'text...</td>\n",
       "      <td>language:\\n- en\\nlicense: llama3.1\\nlibrary_na...</td>\n",
       "      <td>70553706496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>facebook/MobileLLM-1B</td>\n",
       "      <td>facebook/MobileLLM-1B</td>\n",
       "      <td>2024-10-31 00:07:47+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>3770</td>\n",
       "      <td>92</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 1046421760...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['MobileLLMForCausalLM']</td>\n",
       "      <td>['transformers', 'pytorch', 'safetensors', 'mo...</td>\n",
       "      <td>license: cc-by-nc-4.0\\nlibrary_name: transformers</td>\n",
       "      <td>1046421760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meta-llama/Llama-3.2-1B</td>\n",
       "      <td>meta-llama/Llama-3.2-1B</td>\n",
       "      <td>2024-09-18 15:03:14+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1293208</td>\n",
       "      <td>797</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 1235814400...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['LlamaForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'llama', 'text...</td>\n",
       "      <td>language:\\n- en\\n- de\\n- fr\\n- it\\n- pt\\n- hi\\...</td>\n",
       "      <td>1235814400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>facebook/MobileLLM-125M</td>\n",
       "      <td>facebook/MobileLLM-125M</td>\n",
       "      <td>2024-10-30 22:48:34+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>3406</td>\n",
       "      <td>70</td>\n",
       "      <td>SafeTensorsInfo(parameters={'F16': 124635456},...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['MobileLLMForCausalLM']</td>\n",
       "      <td>['transformers', 'pytorch', 'safetensors', 'mo...</td>\n",
       "      <td>license: cc-by-nc-4.0\\nlibrary_name: transformers</td>\n",
       "      <td>124635456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       model  \\\n",
       "0        HuggingFaceTB/SmolLM2-1.7B-Instruct   \n",
       "1  nvidia/Llama-3.1-Nemotron-70B-Instruct-HF   \n",
       "2                      facebook/MobileLLM-1B   \n",
       "3                    meta-llama/Llama-3.2-1B   \n",
       "4                    facebook/MobileLLM-125M   \n",
       "\n",
       "                                          id                 created_at  \\\n",
       "0        HuggingFaceTB/SmolLM2-1.7B-Instruct  2024-10-31 13:42:06+00:00   \n",
       "1  nvidia/Llama-3.1-Nemotron-70B-Instruct-HF  2024-10-12 02:37:13+00:00   \n",
       "2                      facebook/MobileLLM-1B  2024-10-31 00:07:47+00:00   \n",
       "3                    meta-llama/Llama-3.2-1B  2024-09-18 15:03:14+00:00   \n",
       "4                    facebook/MobileLLM-125M  2024-10-30 22:48:34+00:00   \n",
       "\n",
       "  downloads_all_time  downloads  likes  \\\n",
       "0            Unknown      16940    233   \n",
       "1            Unknown     186569   1495   \n",
       "2            Unknown       3770     92   \n",
       "3            Unknown    1293208    797   \n",
       "4            Unknown       3406     70   \n",
       "\n",
       "                                         safetensors             task  \\\n",
       "0  SafeTensorsInfo(parameters={'BF16': 1711376384...  text-generation   \n",
       "1  SafeTensorsInfo(parameters={'BF16': 7055370649...  text-generation   \n",
       "2  SafeTensorsInfo(parameters={'BF16': 1046421760...  text-generation   \n",
       "3  SafeTensorsInfo(parameters={'BF16': 1235814400...  text-generation   \n",
       "4  SafeTensorsInfo(parameters={'F16': 124635456},...  text-generation   \n",
       "\n",
       "                datasets eval_results metrics  library_name  \\\n",
       "0                    NaN          NaN     NaN  transformers   \n",
       "1  ['nvidia/HelpSteer2']          NaN     NaN  transformers   \n",
       "2                    NaN          NaN     NaN  transformers   \n",
       "3                    NaN          NaN     NaN  transformers   \n",
       "4                    NaN          NaN     NaN  transformers   \n",
       "\n",
       "                                   transformers_info  \\\n",
       "0  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "1  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "2  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "3  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "4  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "\n",
       "               architecture  \\\n",
       "0      ['LlamaForCausalLM']   \n",
       "1      ['LlamaForCausalLM']   \n",
       "2  ['MobileLLMForCausalLM']   \n",
       "3      ['LlamaForCausalLM']   \n",
       "4  ['MobileLLMForCausalLM']   \n",
       "\n",
       "                                                tags  \\\n",
       "0  ['transformers', 'tensorboard', 'onnx', 'safet...   \n",
       "1  ['transformers', 'safetensors', 'llama', 'text...   \n",
       "2  ['transformers', 'pytorch', 'safetensors', 'mo...   \n",
       "3  ['transformers', 'safetensors', 'llama', 'text...   \n",
       "4  ['transformers', 'pytorch', 'safetensors', 'mo...   \n",
       "\n",
       "                                           card_data  num_parameters  \n",
       "0  language:\\n- en\\nlicense: apache-2.0\\nlibrary_...      1711376384  \n",
       "1  language:\\n- en\\nlicense: llama3.1\\nlibrary_na...     70553706496  \n",
       "2  license: cc-by-nc-4.0\\nlibrary_name: transformers      1046421760  \n",
       "3  language:\\n- en\\n- de\\n- fr\\n- it\\n- pt\\n- hi\\...      1235814400  \n",
       "4  license: cc-by-nc-4.0\\nlibrary_name: transformers       124635456  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature: Adding num_parameters column\n",
    "\n",
    "# Function to extract the 'total' value from the 'safetensors' string\n",
    "def extract_total(safetensors_info):\n",
    "    if pd.isna(safetensors_info):\n",
    "        return None\n",
    "    match = re.search(r\"total=(\\d+)\", safetensors_info)\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "# Create a new column 'num_parameters' with the extracted total\n",
    "filtered_df['num_parameters'] = filtered_df['safetensors'].apply(extract_total)\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67761\n",
      "limit of num_parameters considered: 5000000000.0\n",
      "32242\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>downloads_all_time</th>\n",
       "      <th>downloads</th>\n",
       "      <th>likes</th>\n",
       "      <th>safetensors</th>\n",
       "      <th>task</th>\n",
       "      <th>datasets</th>\n",
       "      <th>eval_results</th>\n",
       "      <th>metrics</th>\n",
       "      <th>library_name</th>\n",
       "      <th>transformers_info</th>\n",
       "      <th>architecture</th>\n",
       "      <th>tags</th>\n",
       "      <th>card_data</th>\n",
       "      <th>num_parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HuggingFaceTB/SmolLM2-1.7B-Instruct</td>\n",
       "      <td>HuggingFaceTB/SmolLM2-1.7B-Instruct</td>\n",
       "      <td>2024-10-31 13:42:06+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>16940</td>\n",
       "      <td>233</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 1711376384...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['LlamaForCausalLM']</td>\n",
       "      <td>['transformers', 'tensorboard', 'onnx', 'safet...</td>\n",
       "      <td>language:\\n- en\\nlicense: apache-2.0\\nlibrary_...</td>\n",
       "      <td>1711376384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>facebook/MobileLLM-1B</td>\n",
       "      <td>facebook/MobileLLM-1B</td>\n",
       "      <td>2024-10-31 00:07:47+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>3770</td>\n",
       "      <td>92</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 1046421760...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['MobileLLMForCausalLM']</td>\n",
       "      <td>['transformers', 'pytorch', 'safetensors', 'mo...</td>\n",
       "      <td>license: cc-by-nc-4.0\\nlibrary_name: transformers</td>\n",
       "      <td>1046421760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meta-llama/Llama-3.2-1B</td>\n",
       "      <td>meta-llama/Llama-3.2-1B</td>\n",
       "      <td>2024-09-18 15:03:14+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1293208</td>\n",
       "      <td>797</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 1235814400...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['LlamaForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'llama', 'text...</td>\n",
       "      <td>language:\\n- en\\n- de\\n- fr\\n- it\\n- pt\\n- hi\\...</td>\n",
       "      <td>1235814400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>facebook/MobileLLM-125M</td>\n",
       "      <td>facebook/MobileLLM-125M</td>\n",
       "      <td>2024-10-30 22:48:34+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>3406</td>\n",
       "      <td>70</td>\n",
       "      <td>SafeTensorsInfo(parameters={'F16': 124635456},...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['MobileLLMForCausalLM']</td>\n",
       "      <td>['transformers', 'pytorch', 'safetensors', 'mo...</td>\n",
       "      <td>license: cc-by-nc-4.0\\nlibrary_name: transformers</td>\n",
       "      <td>124635456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>meta-llama/Llama-3.2-3B-Instruct</td>\n",
       "      <td>meta-llama/Llama-3.2-3B-Instruct</td>\n",
       "      <td>2024-09-18 15:19:20+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1041938</td>\n",
       "      <td>523</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 3212749824...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['LlamaForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'llama', 'text...</td>\n",
       "      <td>language:\\n- en\\n- de\\n- fr\\n- it\\n- pt\\n- hi\\...</td>\n",
       "      <td>3212749824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model                                   id  \\\n",
       "0  HuggingFaceTB/SmolLM2-1.7B-Instruct  HuggingFaceTB/SmolLM2-1.7B-Instruct   \n",
       "2                facebook/MobileLLM-1B                facebook/MobileLLM-1B   \n",
       "3              meta-llama/Llama-3.2-1B              meta-llama/Llama-3.2-1B   \n",
       "4              facebook/MobileLLM-125M              facebook/MobileLLM-125M   \n",
       "5     meta-llama/Llama-3.2-3B-Instruct     meta-llama/Llama-3.2-3B-Instruct   \n",
       "\n",
       "                  created_at downloads_all_time  downloads  likes  \\\n",
       "0  2024-10-31 13:42:06+00:00            Unknown      16940    233   \n",
       "2  2024-10-31 00:07:47+00:00            Unknown       3770     92   \n",
       "3  2024-09-18 15:03:14+00:00            Unknown    1293208    797   \n",
       "4  2024-10-30 22:48:34+00:00            Unknown       3406     70   \n",
       "5  2024-09-18 15:19:20+00:00            Unknown    1041938    523   \n",
       "\n",
       "                                         safetensors             task  \\\n",
       "0  SafeTensorsInfo(parameters={'BF16': 1711376384...  text-generation   \n",
       "2  SafeTensorsInfo(parameters={'BF16': 1046421760...  text-generation   \n",
       "3  SafeTensorsInfo(parameters={'BF16': 1235814400...  text-generation   \n",
       "4  SafeTensorsInfo(parameters={'F16': 124635456},...  text-generation   \n",
       "5  SafeTensorsInfo(parameters={'BF16': 3212749824...  text-generation   \n",
       "\n",
       "  datasets eval_results metrics  library_name  \\\n",
       "0      NaN          NaN     NaN  transformers   \n",
       "2      NaN          NaN     NaN  transformers   \n",
       "3      NaN          NaN     NaN  transformers   \n",
       "4      NaN          NaN     NaN  transformers   \n",
       "5      NaN          NaN     NaN  transformers   \n",
       "\n",
       "                                   transformers_info  \\\n",
       "0  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "2  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "3  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "4  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "5  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "\n",
       "               architecture  \\\n",
       "0      ['LlamaForCausalLM']   \n",
       "2  ['MobileLLMForCausalLM']   \n",
       "3      ['LlamaForCausalLM']   \n",
       "4  ['MobileLLMForCausalLM']   \n",
       "5      ['LlamaForCausalLM']   \n",
       "\n",
       "                                                tags  \\\n",
       "0  ['transformers', 'tensorboard', 'onnx', 'safet...   \n",
       "2  ['transformers', 'pytorch', 'safetensors', 'mo...   \n",
       "3  ['transformers', 'safetensors', 'llama', 'text...   \n",
       "4  ['transformers', 'pytorch', 'safetensors', 'mo...   \n",
       "5  ['transformers', 'safetensors', 'llama', 'text...   \n",
       "\n",
       "                                           card_data  num_parameters  \n",
       "0  language:\\n- en\\nlicense: apache-2.0\\nlibrary_...      1711376384  \n",
       "2  license: cc-by-nc-4.0\\nlibrary_name: transformers      1046421760  \n",
       "3  language:\\n- en\\n- de\\n- fr\\n- it\\n- pt\\n- hi\\...      1235814400  \n",
       "4  license: cc-by-nc-4.0\\nlibrary_name: transformers       124635456  \n",
       "5  language:\\n- en\\n- de\\n- fr\\n- it\\n- pt\\n- hi\\...      3212749824  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out rows where the 'safetensors' column is NaN\n",
    "limit_slm_parameters=5 *1e9 # 10B\n",
    "print(len(filtered_df))\n",
    "print(f'limit of num_parameters considered: {limit_slm_parameters}')\n",
    "filtered_df = filtered_df[filtered_df['num_parameters'] <= limit_slm_parameters]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(len(filtered_df))\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "likes max: 3239 downloads max: 15341589\n",
      "popularity max: 1.7246063599876504 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>downloads_all_time</th>\n",
       "      <th>downloads</th>\n",
       "      <th>likes</th>\n",
       "      <th>safetensors</th>\n",
       "      <th>task</th>\n",
       "      <th>datasets</th>\n",
       "      <th>eval_results</th>\n",
       "      <th>metrics</th>\n",
       "      <th>library_name</th>\n",
       "      <th>transformers_info</th>\n",
       "      <th>architecture</th>\n",
       "      <th>tags</th>\n",
       "      <th>card_data</th>\n",
       "      <th>num_parameters</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HuggingFaceTB/SmolLM2-1.7B-Instruct</td>\n",
       "      <td>HuggingFaceTB/SmolLM2-1.7B-Instruct</td>\n",
       "      <td>2024-10-31 13:42:06+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>16940</td>\n",
       "      <td>233</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 1711376384...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['LlamaForCausalLM']</td>\n",
       "      <td>['transformers', 'tensorboard', 'onnx', 'safet...</td>\n",
       "      <td>language:\\n- en\\nlicense: apache-2.0\\nlibrary_...</td>\n",
       "      <td>1711376384</td>\n",
       "      <td>0.073040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>facebook/MobileLLM-1B</td>\n",
       "      <td>facebook/MobileLLM-1B</td>\n",
       "      <td>2024-10-31 00:07:47+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>3770</td>\n",
       "      <td>92</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 1046421760...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['MobileLLMForCausalLM']</td>\n",
       "      <td>['transformers', 'pytorch', 'safetensors', 'mo...</td>\n",
       "      <td>license: cc-by-nc-4.0\\nlibrary_name: transformers</td>\n",
       "      <td>1046421760</td>\n",
       "      <td>0.028650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meta-llama/Llama-3.2-1B</td>\n",
       "      <td>meta-llama/Llama-3.2-1B</td>\n",
       "      <td>2024-09-18 15:03:14+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1293208</td>\n",
       "      <td>797</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 1235814400...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['LlamaForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'llama', 'text...</td>\n",
       "      <td>language:\\n- en\\n- de\\n- fr\\n- it\\n- pt\\n- hi\\...</td>\n",
       "      <td>1235814400</td>\n",
       "      <td>0.330358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>facebook/MobileLLM-125M</td>\n",
       "      <td>facebook/MobileLLM-125M</td>\n",
       "      <td>2024-10-30 22:48:34+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>3406</td>\n",
       "      <td>70</td>\n",
       "      <td>SafeTensorsInfo(parameters={'F16': 124635456},...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['MobileLLMForCausalLM']</td>\n",
       "      <td>['transformers', 'pytorch', 'safetensors', 'mo...</td>\n",
       "      <td>license: cc-by-nc-4.0\\nlibrary_name: transformers</td>\n",
       "      <td>124635456</td>\n",
       "      <td>0.021834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>meta-llama/Llama-3.2-3B-Instruct</td>\n",
       "      <td>meta-llama/Llama-3.2-3B-Instruct</td>\n",
       "      <td>2024-09-18 15:19:20+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1041938</td>\n",
       "      <td>523</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 3212749824...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['LlamaForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'llama', 'text...</td>\n",
       "      <td>language:\\n- en\\n- de\\n- fr\\n- it\\n- pt\\n- hi\\...</td>\n",
       "      <td>3212749824</td>\n",
       "      <td>0.229386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model                                   id  \\\n",
       "0  HuggingFaceTB/SmolLM2-1.7B-Instruct  HuggingFaceTB/SmolLM2-1.7B-Instruct   \n",
       "2                facebook/MobileLLM-1B                facebook/MobileLLM-1B   \n",
       "3              meta-llama/Llama-3.2-1B              meta-llama/Llama-3.2-1B   \n",
       "4              facebook/MobileLLM-125M              facebook/MobileLLM-125M   \n",
       "5     meta-llama/Llama-3.2-3B-Instruct     meta-llama/Llama-3.2-3B-Instruct   \n",
       "\n",
       "                  created_at downloads_all_time  downloads  likes  \\\n",
       "0  2024-10-31 13:42:06+00:00            Unknown      16940    233   \n",
       "2  2024-10-31 00:07:47+00:00            Unknown       3770     92   \n",
       "3  2024-09-18 15:03:14+00:00            Unknown    1293208    797   \n",
       "4  2024-10-30 22:48:34+00:00            Unknown       3406     70   \n",
       "5  2024-09-18 15:19:20+00:00            Unknown    1041938    523   \n",
       "\n",
       "                                         safetensors             task  \\\n",
       "0  SafeTensorsInfo(parameters={'BF16': 1711376384...  text-generation   \n",
       "2  SafeTensorsInfo(parameters={'BF16': 1046421760...  text-generation   \n",
       "3  SafeTensorsInfo(parameters={'BF16': 1235814400...  text-generation   \n",
       "4  SafeTensorsInfo(parameters={'F16': 124635456},...  text-generation   \n",
       "5  SafeTensorsInfo(parameters={'BF16': 3212749824...  text-generation   \n",
       "\n",
       "  datasets eval_results metrics  library_name  \\\n",
       "0      NaN          NaN     NaN  transformers   \n",
       "2      NaN          NaN     NaN  transformers   \n",
       "3      NaN          NaN     NaN  transformers   \n",
       "4      NaN          NaN     NaN  transformers   \n",
       "5      NaN          NaN     NaN  transformers   \n",
       "\n",
       "                                   transformers_info  \\\n",
       "0  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "2  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "3  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "4  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "5  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "\n",
       "               architecture  \\\n",
       "0      ['LlamaForCausalLM']   \n",
       "2  ['MobileLLMForCausalLM']   \n",
       "3      ['LlamaForCausalLM']   \n",
       "4  ['MobileLLMForCausalLM']   \n",
       "5      ['LlamaForCausalLM']   \n",
       "\n",
       "                                                tags  \\\n",
       "0  ['transformers', 'tensorboard', 'onnx', 'safet...   \n",
       "2  ['transformers', 'pytorch', 'safetensors', 'mo...   \n",
       "3  ['transformers', 'safetensors', 'llama', 'text...   \n",
       "4  ['transformers', 'pytorch', 'safetensors', 'mo...   \n",
       "5  ['transformers', 'safetensors', 'llama', 'text...   \n",
       "\n",
       "                                           card_data  num_parameters  \\\n",
       "0  language:\\n- en\\nlicense: apache-2.0\\nlibrary_...      1711376384   \n",
       "2  license: cc-by-nc-4.0\\nlibrary_name: transformers      1046421760   \n",
       "3  language:\\n- en\\n- de\\n- fr\\n- it\\n- pt\\n- hi\\...      1235814400   \n",
       "4  license: cc-by-nc-4.0\\nlibrary_name: transformers       124635456   \n",
       "5  language:\\n- en\\n- de\\n- fr\\n- it\\n- pt\\n- hi\\...      3212749824   \n",
       "\n",
       "   popularity  \n",
       "0    0.073040  \n",
       "2    0.028650  \n",
       "3    0.330358  \n",
       "4    0.021834  \n",
       "5    0.229386  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature: Adding popularity column: sum of normalized likes and downloads\n",
    "\n",
    "# Normalize the 'likes' and 'downloads' columns\n",
    "#filtered_df['normalized_likes'] = df['likes'] / df['likes'].max()\n",
    "#df['normalized_downloads'] = df['downloads'] / df['downloads'].max()\n",
    "\n",
    "# Calculate the sum of the normalized 'likes' and 'downloads'\n",
    "print(f\"likes max: {filtered_df['likes'].max()} downloads max: {filtered_df['downloads'].max()}\")\n",
    "filtered_df['popularity'] = (filtered_df['likes'] / filtered_df['likes'].max()) + (filtered_df['downloads'] / filtered_df['downloads'].max())\n",
    "print(f\"popularity max: {filtered_df['popularity'].max()} \")\n",
    "\n",
    "\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Filter rows where 'card_data' contains the string 'humaneval' (case-insensitive)\n",
    "# df_test = filtered_df[\n",
    "#     filtered_df['card_data'].str.contains('humaneval', case=False, na=False)\n",
    "# ]\n",
    "\n",
    "# # Display the length of the filtered DataFrame\n",
    "# print(\"Filtered DataFrame Length:\", len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(check_model(\"microsoft/Phi-3-mini-128k-instruct\" ,filtered_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"microsoft/Phi-3-mini-128k-instruct\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32242\n"
     ]
    }
   ],
   "source": [
    "print(len(filtered_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filtered_df['humaneval_in_card'] = filtered_df['card_data'].str.contains('humaneval', case=False, na=False)\n",
    "\n",
    "filtered_df['humaneval_in_eval_results'] = filtered_df['eval_results'].str.contains('humaneval', case=False, na=False)\n",
    "\n",
    "filtered_df['need_permission'] = filtered_df['card_data'].str.contains('extra_gated', case=False, na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>downloads_all_time</th>\n",
       "      <th>downloads</th>\n",
       "      <th>likes</th>\n",
       "      <th>safetensors</th>\n",
       "      <th>task</th>\n",
       "      <th>datasets</th>\n",
       "      <th>eval_results</th>\n",
       "      <th>...</th>\n",
       "      <th>library_name</th>\n",
       "      <th>transformers_info</th>\n",
       "      <th>architecture</th>\n",
       "      <th>tags</th>\n",
       "      <th>card_data</th>\n",
       "      <th>num_parameters</th>\n",
       "      <th>popularity</th>\n",
       "      <th>humaneval_in_card</th>\n",
       "      <th>humaneval_in_eval_results</th>\n",
       "      <th>need_permission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>microsoft/Phi-3-mini-128k-instruct</td>\n",
       "      <td>microsoft/Phi-3-mini-128k-instruct</td>\n",
       "      <td>2024-04-22 16:26:23+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>529382</td>\n",
       "      <td>1598</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 3821079552...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['Phi3ForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'phi3', 'text-...</td>\n",
       "      <td>language:\\n- en\\nlicense: mit\\ntags:\\n- nlp\\n-...</td>\n",
       "      <td>3821079552</td>\n",
       "      <td>0.527868</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model                                  id  \\\n",
       "79  microsoft/Phi-3-mini-128k-instruct  microsoft/Phi-3-mini-128k-instruct   \n",
       "\n",
       "                   created_at downloads_all_time  downloads  likes  \\\n",
       "79  2024-04-22 16:26:23+00:00            Unknown     529382   1598   \n",
       "\n",
       "                                          safetensors             task  \\\n",
       "79  SafeTensorsInfo(parameters={'BF16': 3821079552...  text-generation   \n",
       "\n",
       "   datasets eval_results  ...  library_name  \\\n",
       "79      NaN          NaN  ...  transformers   \n",
       "\n",
       "                                    transformers_info         architecture  \\\n",
       "79  TransformersInfo(auto_model='AutoModelForCausa...  ['Phi3ForCausalLM']   \n",
       "\n",
       "                                                 tags  \\\n",
       "79  ['transformers', 'safetensors', 'phi3', 'text-...   \n",
       "\n",
       "                                            card_data num_parameters  \\\n",
       "79  language:\\n- en\\nlicense: mit\\ntags:\\n- nlp\\n-...     3821079552   \n",
       "\n",
       "    popularity  humaneval_in_card  humaneval_in_eval_results  need_permission  \n",
       "79    0.527868              False                      False            False  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemma = filtered_df[filtered_df['model'] == model_name]\n",
    "\n",
    "gemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered DataFrame Length: 430\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>downloads_all_time</th>\n",
       "      <th>downloads</th>\n",
       "      <th>likes</th>\n",
       "      <th>safetensors</th>\n",
       "      <th>task</th>\n",
       "      <th>datasets</th>\n",
       "      <th>eval_results</th>\n",
       "      <th>...</th>\n",
       "      <th>library_name</th>\n",
       "      <th>transformers_info</th>\n",
       "      <th>architecture</th>\n",
       "      <th>tags</th>\n",
       "      <th>card_data</th>\n",
       "      <th>num_parameters</th>\n",
       "      <th>popularity</th>\n",
       "      <th>humaneval_in_card</th>\n",
       "      <th>humaneval_in_eval_results</th>\n",
       "      <th>need_permission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meta-llama/Llama-3.2-1B</td>\n",
       "      <td>meta-llama/Llama-3.2-1B</td>\n",
       "      <td>2024-09-18 15:03:14+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1293208</td>\n",
       "      <td>797</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 1235814400...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['LlamaForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'llama', 'text...</td>\n",
       "      <td>language:\\n- en\\n- de\\n- fr\\n- it\\n- pt\\n- hi\\...</td>\n",
       "      <td>1235814400</td>\n",
       "      <td>0.330358</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>meta-llama/Llama-3.2-3B-Instruct</td>\n",
       "      <td>meta-llama/Llama-3.2-3B-Instruct</td>\n",
       "      <td>2024-09-18 15:19:20+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1041938</td>\n",
       "      <td>523</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 3212749824...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['LlamaForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'llama', 'text...</td>\n",
       "      <td>language:\\n- en\\n- de\\n- fr\\n- it\\n- pt\\n- hi\\...</td>\n",
       "      <td>3212749824</td>\n",
       "      <td>0.229386</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>meta-llama/Llama-3.2-1B-Instruct</td>\n",
       "      <td>meta-llama/Llama-3.2-1B-Instruct</td>\n",
       "      <td>2024-09-18 15:12:47+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1318521</td>\n",
       "      <td>504</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 1235814400...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['LlamaForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'llama', 'text...</td>\n",
       "      <td>language:\\n- en\\n- de\\n- fr\\n- it\\n- pt\\n- hi\\...</td>\n",
       "      <td>1235814400</td>\n",
       "      <td>0.241548</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>meta-llama/Llama-3.2-3B</td>\n",
       "      <td>meta-llama/Llama-3.2-3B</td>\n",
       "      <td>2024-09-18 15:23:48+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>248764</td>\n",
       "      <td>292</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 3212749824...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['LlamaForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'llama', 'text...</td>\n",
       "      <td>language:\\n- en\\n- de\\n- fr\\n- it\\n- pt\\n- hi\\...</td>\n",
       "      <td>3212749824</td>\n",
       "      <td>0.106366</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>google/gemma-2-2b</td>\n",
       "      <td>google/gemma-2-2b</td>\n",
       "      <td>2024-07-16 08:07:29+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>13477941</td>\n",
       "      <td>403</td>\n",
       "      <td>SafeTensorsInfo(parameters={'F32': 2614341888}...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['Gemma2ForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'gemma2', 'tex...</td>\n",
       "      <td>license: gemma\\nlibrary_name: transformers\\npi...</td>\n",
       "      <td>2614341888</td>\n",
       "      <td>1.002944</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               model                                id  \\\n",
       "3            meta-llama/Llama-3.2-1B           meta-llama/Llama-3.2-1B   \n",
       "5   meta-llama/Llama-3.2-3B-Instruct  meta-llama/Llama-3.2-3B-Instruct   \n",
       "10  meta-llama/Llama-3.2-1B-Instruct  meta-llama/Llama-3.2-1B-Instruct   \n",
       "16           meta-llama/Llama-3.2-3B           meta-llama/Llama-3.2-3B   \n",
       "34                 google/gemma-2-2b                 google/gemma-2-2b   \n",
       "\n",
       "                   created_at downloads_all_time  downloads  likes  \\\n",
       "3   2024-09-18 15:03:14+00:00            Unknown    1293208    797   \n",
       "5   2024-09-18 15:19:20+00:00            Unknown    1041938    523   \n",
       "10  2024-09-18 15:12:47+00:00            Unknown    1318521    504   \n",
       "16  2024-09-18 15:23:48+00:00            Unknown     248764    292   \n",
       "34  2024-07-16 08:07:29+00:00            Unknown   13477941    403   \n",
       "\n",
       "                                          safetensors             task  \\\n",
       "3   SafeTensorsInfo(parameters={'BF16': 1235814400...  text-generation   \n",
       "5   SafeTensorsInfo(parameters={'BF16': 3212749824...  text-generation   \n",
       "10  SafeTensorsInfo(parameters={'BF16': 1235814400...  text-generation   \n",
       "16  SafeTensorsInfo(parameters={'BF16': 3212749824...  text-generation   \n",
       "34  SafeTensorsInfo(parameters={'F32': 2614341888}...  text-generation   \n",
       "\n",
       "   datasets eval_results  ...  library_name  \\\n",
       "3       NaN          NaN  ...  transformers   \n",
       "5       NaN          NaN  ...  transformers   \n",
       "10      NaN          NaN  ...  transformers   \n",
       "16      NaN          NaN  ...  transformers   \n",
       "34      NaN          NaN  ...  transformers   \n",
       "\n",
       "                                    transformers_info           architecture  \\\n",
       "3   TransformersInfo(auto_model='AutoModelForCausa...   ['LlamaForCausalLM']   \n",
       "5   TransformersInfo(auto_model='AutoModelForCausa...   ['LlamaForCausalLM']   \n",
       "10  TransformersInfo(auto_model='AutoModelForCausa...   ['LlamaForCausalLM']   \n",
       "16  TransformersInfo(auto_model='AutoModelForCausa...   ['LlamaForCausalLM']   \n",
       "34  TransformersInfo(auto_model='AutoModelForCausa...  ['Gemma2ForCausalLM']   \n",
       "\n",
       "                                                 tags  \\\n",
       "3   ['transformers', 'safetensors', 'llama', 'text...   \n",
       "5   ['transformers', 'safetensors', 'llama', 'text...   \n",
       "10  ['transformers', 'safetensors', 'llama', 'text...   \n",
       "16  ['transformers', 'safetensors', 'llama', 'text...   \n",
       "34  ['transformers', 'safetensors', 'gemma2', 'tex...   \n",
       "\n",
       "                                            card_data num_parameters  \\\n",
       "3   language:\\n- en\\n- de\\n- fr\\n- it\\n- pt\\n- hi\\...     1235814400   \n",
       "5   language:\\n- en\\n- de\\n- fr\\n- it\\n- pt\\n- hi\\...     3212749824   \n",
       "10  language:\\n- en\\n- de\\n- fr\\n- it\\n- pt\\n- hi\\...     1235814400   \n",
       "16  language:\\n- en\\n- de\\n- fr\\n- it\\n- pt\\n- hi\\...     3212749824   \n",
       "34  license: gemma\\nlibrary_name: transformers\\npi...     2614341888   \n",
       "\n",
       "    popularity  humaneval_in_card  humaneval_in_eval_results  need_permission  \n",
       "3     0.330358              False                      False             True  \n",
       "5     0.229386              False                      False             True  \n",
       "10    0.241548              False                      False             True  \n",
       "16    0.106366              False                      False             True  \n",
       "34    1.002944              False                      False             True  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter rows where any of the specified columns have a True value\n",
    "filtered_df = filtered_df[\n",
    "    filtered_df[['humaneval_in_card', 'humaneval_in_eval_results', 'need_permission']].any(axis=1)\n",
    "]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(\"Filtered DataFrame Length:\", len(filtered_df))\n",
    "filtered_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # filter models with humaneval_in_card = False and need_permission = False\n",
    "\n",
    "\n",
    "# # Apply the filter conditionally based on 'need_permission' and 'humaneval_in_card' columns\n",
    "# filtered_df = filtered_df[\n",
    "#     ((filtered_df['need_permission']) & (filtered_df['humaneval_in_card'])) | \n",
    "#     filtered_df['eval_results'].apply(\n",
    "#         lambda x: not (isinstance(x, list) and len(x) == 0) and x != \"[]\" and pd.notna(x)\n",
    "#     )\n",
    "# ]\n",
    "\n",
    "# # Display the filtered DataFrame\n",
    "# print(\"Filtered DataFrame Length:\", len(filtered_df))\n",
    "# filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with eval results or humaneval in card_data: 1941\n",
      "False\n",
      "After humaneval in eval_results:  183\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Filter out rows where the 'safetensors' column is NaN\n",
    "# filtered_df = filtered_df[ \n",
    "        \n",
    "#     filtered_df['eval_results'].apply(\n",
    "#         lambda x: not (isinstance(x, list) and len(x) == 0) and x != \"[]\" and pd.notna(x)\n",
    "#         )\n",
    "#     or filtered_df['card_data'].str.contains('humaneval', case=False, na=False)\n",
    "# ]\n",
    "\n",
    "# filtered_df = filtered_df[\n",
    "#     filtered_df['card_data'].str.contains('humaneval', case=False, na=False)\n",
    "    \n",
    "#     | filtered_df['eval_results'].apply(\n",
    "#         lambda x: not (isinstance(x, list) and len(x) == 0) and x != \"[]\" and pd.notna(x)\n",
    "#     ) \n",
    "    \n",
    "# ]\n",
    "\n",
    "# print(\"with eval results or humaneval in card_data:\", len(filtered_df))\n",
    "\n",
    "# print(check_model(\"google/gemma-2-2b\" ,filtered_df))\n",
    "\n",
    "# import re\n",
    "\n",
    "# # Define a regex pattern to match 'dataset_name' containing 'humaneval' (case insensitive)\n",
    "# pattern = r\"dataset_name=['\\\"]humaneval['\\\"]\" # there are other like 'humanevalsynthesis'\n",
    "\n",
    "# # Filter rows where 'eval_results' matches the regex pattern\n",
    "# filtered_df = filtered_df[\n",
    "#     filtered_df['eval_results'].str.contains(pattern, case=False, na=False) |\n",
    "#     filtered_df['card_data'].str.contains('humaneval', case=False, na=False)\n",
    "# ]\n",
    "\n",
    "# print(\"After humaneval in eval_results: \",len(filtered_df))\n",
    "\n",
    "# print(check_model(\"google/gemma-2-2b\" ,filtered_df))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered CSV file saved: model_selection/tmp/evaluated_models.csv\n"
     ]
    }
   ],
   "source": [
    "save_evaluated_df =True\n",
    "save_dir = 'model_selection/tmp/'\n",
    "if save_evaluated_df:\n",
    "    # Optional: Save the filtered DataFrame to a CSV file\n",
    "    filtered_df.to_csv(save_dir + \"evaluated_models.csv\", index=False)\n",
    "    print(f\"Filtered CSV file saved: {save_dir}evaluated_models.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering all models without date filter\n"
     ]
    }
   ],
   "source": [
    "# If filter by any date\n",
    "filtered_df['created_at'] = pd.to_datetime(filtered_df['created_at'], errors='coerce')\n",
    "\n",
    "filter_date = False\n",
    "if filter_date :\n",
    "    # Filter models with 'created_at' in 2023 or later\n",
    "    year = 2021\n",
    "    filtered_df = filtered_df[filtered_df['created_at'].dt.year >= year]\n",
    "\n",
    "    print(f\"filtered w/ created_at len now:{len(filtered_df)}\")\n",
    "else:\n",
    "    print(\"Considering all models without date filter\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>card_data</th>\n",
       "      <th>base_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meta-llama/Llama-3.2-1B</td>\n",
       "      <td>language:\\n- en\\n- de\\n- fr\\n- it\\n- pt\\n- hi\\...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>meta-llama/Llama-3.2-3B-Instruct</td>\n",
       "      <td>language:\\n- en\\n- de\\n- fr\\n- it\\n- pt\\n- hi\\...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>meta-llama/Llama-3.2-1B-Instruct</td>\n",
       "      <td>language:\\n- en\\n- de\\n- fr\\n- it\\n- pt\\n- hi\\...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>meta-llama/Llama-3.2-3B</td>\n",
       "      <td>language:\\n- en\\n- de\\n- fr\\n- it\\n- pt\\n- hi\\...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>google/gemma-2-2b</td>\n",
       "      <td>license: gemma\\nlibrary_name: transformers\\npi...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>google/gemma-2-2b-it</td>\n",
       "      <td>license: gemma\\nlibrary_name: transformers\\nta...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>google/gemma-2-2b-jpn-it</td>\n",
       "      <td>language:\\n- ja\\nlicense: gemma\\nlibrary_name:...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>ibm-granite/granite-3.0-2b-instruct</td>\n",
       "      <td>license: apache-2.0\\nlibrary_name: transformer...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>meta-llama/Llama-Guard-3-1B</td>\n",
       "      <td>language:\\n- en\\n- de\\n- fr\\n- it\\n- pt\\n- hi\\...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>NousResearch/Llama-3.2-1B</td>\n",
       "      <td>language:\\n- en\\n- de\\n- fr\\n- it\\n- pt\\n- hi\\...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   model  \\\n",
       "3                meta-llama/Llama-3.2-1B   \n",
       "5       meta-llama/Llama-3.2-3B-Instruct   \n",
       "10      meta-llama/Llama-3.2-1B-Instruct   \n",
       "16               meta-llama/Llama-3.2-3B   \n",
       "34                     google/gemma-2-2b   \n",
       "36                  google/gemma-2-2b-it   \n",
       "86              google/gemma-2-2b-jpn-it   \n",
       "89   ibm-granite/granite-3.0-2b-instruct   \n",
       "161          meta-llama/Llama-Guard-3-1B   \n",
       "163            NousResearch/Llama-3.2-1B   \n",
       "\n",
       "                                             card_data  base_model  \n",
       "3    language:\\n- en\\n- de\\n- fr\\n- it\\n- pt\\n- hi\\...        True  \n",
       "5    language:\\n- en\\n- de\\n- fr\\n- it\\n- pt\\n- hi\\...        True  \n",
       "10   language:\\n- en\\n- de\\n- fr\\n- it\\n- pt\\n- hi\\...        True  \n",
       "16   language:\\n- en\\n- de\\n- fr\\n- it\\n- pt\\n- hi\\...        True  \n",
       "34   license: gemma\\nlibrary_name: transformers\\npi...        True  \n",
       "36   license: gemma\\nlibrary_name: transformers\\nta...       False  \n",
       "86   language:\\n- ja\\nlicense: gemma\\nlibrary_name:...       False  \n",
       "89   license: apache-2.0\\nlibrary_name: transformer...       False  \n",
       "161  language:\\n- en\\n- de\\n- fr\\n- it\\n- pt\\n- hi\\...        True  \n",
       "163  language:\\n- en\\n- de\\n- fr\\n- it\\n- pt\\n- hi\\...        True  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature: base_model False if it has parent model\n",
    "\n",
    "filtered_df['base_model'] = ~filtered_df['card_data'].str.contains('base_model', case=False, na=False)\n",
    "\n",
    "\n",
    "filtered_df[['model','card_data', 'base_model']].head(n=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "430"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of base models == True: 340\n"
     ]
    }
   ],
   "source": [
    "# Count the number of models where 'base_model' is True\n",
    "base_model_count = filtered_df[filtered_df['base_model'] == True].shape[0]\n",
    "\n",
    "# Display the count\n",
    "print(\"Number of base models == True:\", base_model_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered CSV file saved: model_selection/tmp/filtered_models.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "save_filtered_df =True\n",
    "if save_filtered_df:\n",
    "    # Optional: Save the filtered DataFrame to a CSV file\n",
    "    filtered_df.to_csv(save_dir + \"filtered_models.csv\", index=False)\n",
    "    print(f\"Filtered CSV file saved: {save_dir}filtered_models.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model                                                    ibm/PowerLM-3b\n",
       "id                                                       ibm/PowerLM-3b\n",
       "created_at                                    2024-08-14 18:20:58+00:00\n",
       "downloads_all_time                                              Unknown\n",
       "downloads                                                         16449\n",
       "likes                                                                17\n",
       "safetensors           SafeTensorsInfo(parameters={'F32': 3512017152}...\n",
       "task                                                    text-generation\n",
       "datasets                                                            NaN\n",
       "eval_results          [EvalResult(task_type='text-generation', datas...\n",
       "metrics                                                             NaN\n",
       "library_name                                               transformers\n",
       "transformers_info     TransformersInfo(auto_model='AutoModelForCausa...\n",
       "architecture                                     ['GraniteForCausalLM']\n",
       "tags                  ['transformers', 'safetensors', 'granite', 'te...\n",
       "card_data             license: apache-2.0\\nlibrary_name: transformer...\n",
       "num_parameters                                               3512017152\n",
       "popularity                                                     0.003998\n",
       "Name: 2152, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "import random\n",
    "i = random.randint(0,len(filtered_df))\n",
    "print(i)\n",
    "row = filtered_df.iloc[i]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stratified sampling (optional)\n",
    "- Not done for last experiments due to number of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total models: 69\n"
     ]
    }
   ],
   "source": [
    "save_dir = 'model_selection/results/'\n",
    "file_name = save_dir+'filtered_models.csv'\n",
    "df = pd.read_csv(file_name)\n",
    "print(f'total models: {len(df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['model', 'id', 'created_at', 'downloads_all_time', 'downloads', 'likes',\n",
       "       'safetensors', 'task', 'datasets', 'eval_results', 'metrics',\n",
       "       'library_name', 'transformers_info', 'architecture', 'tags',\n",
       "       'card_data', 'num_parameters', 'popularity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add likes: popularity = sum of the normalized likes and downloads\n",
    "stratification_criteria = ['popularity', 'num_parameters','created_at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   popularity_quartile  created_at_quartile  num_parameters_quartile\n",
      "0                    1                    1                        1\n",
      "1                    1                    1                        1\n",
      "2                    1                    0                        0\n",
      "3                    1                    0                        0\n",
      "4                    1                    0                        0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have loaded your DataFrame 'df'\n",
    "\n",
    "# Convert 'created_at' to a numerical format for quartile calculation\n",
    "df['created_at'] = pd.to_datetime(df['created_at'], errors='coerce')\n",
    "df['created_at_numeric'] = df['created_at'].astype(int) // 10**9  # Convert to Unix timestamp, seconds\n",
    "\n",
    "# Create quartiles for stratified sampling\n",
    "df['popularity_quartile'] = pd.qcut(df['popularity'], q=2, labels=False)  # 2 quartiles\n",
    "df['created_at_quartile'] = pd.qcut(df['created_at_numeric'], q=2, labels=False)  # 2 quartiles\n",
    "df['num_parameters_quartile'] = pd.qcut(df['num_parameters'], q=3, labels=False)  # 3 quartiles\n",
    "\n",
    "\n",
    "\n",
    "# Display the DataFrame with new quartile columns\n",
    "print(df[['popularity_quartile', 'created_at_quartile', 'num_parameters_quartile']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered CSV file saved: model_selection/results/selected_models.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_169904/1651244523.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  selected_models = strata.apply(lambda x: x.sample(1)).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>downloads_all_time</th>\n",
       "      <th>downloads</th>\n",
       "      <th>likes</th>\n",
       "      <th>safetensors</th>\n",
       "      <th>task</th>\n",
       "      <th>datasets</th>\n",
       "      <th>eval_results</th>\n",
       "      <th>...</th>\n",
       "      <th>transformers_info</th>\n",
       "      <th>architecture</th>\n",
       "      <th>tags</th>\n",
       "      <th>card_data</th>\n",
       "      <th>num_parameters</th>\n",
       "      <th>popularity</th>\n",
       "      <th>created_at_numeric</th>\n",
       "      <th>popularity_quartile</th>\n",
       "      <th>created_at_quartile</th>\n",
       "      <th>num_parameters_quartile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TheBloke/speechless-code-mistral-7B-v1.0-GPTQ</td>\n",
       "      <td>TheBloke/speechless-code-mistral-7B-v1.0-GPTQ</td>\n",
       "      <td>2023-10-13 06:08:01+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>SafeTensorsInfo(parameters={'I32': 880476160, ...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>['jondurbin/airoboros-2.2', 'Open-Orca/OpenOrc...</td>\n",
       "      <td>[EvalResult(task_type='text-generation', datas...</td>\n",
       "      <td>...</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['MistralForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'mistral', 'te...</td>\n",
       "      <td>language:\\n- en\\nlicense: llama2\\nlibrary_name...</td>\n",
       "      <td>1198788608</td>\n",
       "      <td>6.558938e-03</td>\n",
       "      <td>1697177281</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TheBloke/WizardCoder-Python-13B-V1.0-AWQ</td>\n",
       "      <td>TheBloke/WizardCoder-Python-13B-V1.0-AWQ</td>\n",
       "      <td>2023-09-19 00:53:10+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>SafeTensorsInfo(parameters={'I32': 1598361600,...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[EvalResult(task_type='text-generation', datas...</td>\n",
       "      <td>...</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['LlamaForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'llama', 'text...</td>\n",
       "      <td>license: llama2\\nlibrary_name: transformers\\nt...</td>\n",
       "      <td>2025589760</td>\n",
       "      <td>1.807119e-06</td>\n",
       "      <td>1695084790</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vodkaslime/test-repo-stablecode</td>\n",
       "      <td>vodkaslime/test-repo-stablecode</td>\n",
       "      <td>2023-08-23 07:50:01+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 2769311040...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[EvalResult(task_type='text-generation', datas...</td>\n",
       "      <td>...</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['GPTNeoXForCausalLM']</td>\n",
       "      <td>['transformers', 'pytorch', 'safetensors', 'gp...</td>\n",
       "      <td>language:\\n- code\\nlicense: other\\ntags:\\n- ca...</td>\n",
       "      <td>3306181952</td>\n",
       "      <td>2.710678e-06</td>\n",
       "      <td>1692777001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TechxGenus/starcoder2-3b-GPTQ</td>\n",
       "      <td>TechxGenus/starcoder2-3b-GPTQ</td>\n",
       "      <td>2024-03-22 13:35:25+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>945</td>\n",
       "      <td>1</td>\n",
       "      <td>SafeTensorsInfo(parameters={'I32': 363432960, ...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>['bigcode/the-stack-v2-train']</td>\n",
       "      <td>[EvalResult(task_type='text-generation', datas...</td>\n",
       "      <td>...</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['Starcoder2ForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'starcoder2', ...</td>\n",
       "      <td>license: bigcode-openrail-m\\nlibrary_name: tra...</td>\n",
       "      <td>688945152</td>\n",
       "      <td>3.356312e-03</td>\n",
       "      <td>1711114525</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TechxGenus/starcoder2-15b-AWQ</td>\n",
       "      <td>TechxGenus/starcoder2-15b-AWQ</td>\n",
       "      <td>2024-04-12 14:03:22+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>SafeTensorsInfo(parameters={'I32': 1933885440,...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>['bigcode/the-stack-v2-train']</td>\n",
       "      <td>[EvalResult(task_type='text-generation', datas...</td>\n",
       "      <td>...</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['Starcoder2ForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'starcoder2', ...</td>\n",
       "      <td>license: bigcode-openrail-m\\nlibrary_name: tra...</td>\n",
       "      <td>2661535744</td>\n",
       "      <td>3.280988e-03</td>\n",
       "      <td>1712930602</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nlpguy/granite-3.0-3b-a800m-base</td>\n",
       "      <td>nlpguy/granite-3.0-3b-a800m-base</td>\n",
       "      <td>2024-10-31 14:29:25+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>SafeTensorsInfo(parameters={'F32': 3374286336}...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[EvalResult(task_type='text-generation', datas...</td>\n",
       "      <td>...</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['GraniteMoeForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'granitemoe', ...</td>\n",
       "      <td>license: apache-2.0\\nlibrary_name: transformer...</td>\n",
       "      <td>3374286336</td>\n",
       "      <td>4.107089e-07</td>\n",
       "      <td>1730384965</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TheBloke/WizardCoder-Python-7B-V1.0-AWQ</td>\n",
       "      <td>TheBloke/WizardCoder-Python-7B-V1.0-AWQ</td>\n",
       "      <td>2023-09-19 00:52:16+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>118</td>\n",
       "      <td>2</td>\n",
       "      <td>SafeTensorsInfo(parameters={'I32': 815824896, ...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[EvalResult(task_type='text-generation', datas...</td>\n",
       "      <td>...</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['LlamaForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'llama', 'text...</td>\n",
       "      <td>license: llama2\\nlibrary_name: transformers\\nt...</td>\n",
       "      <td>1128837120</td>\n",
       "      <td>6.567070e-03</td>\n",
       "      <td>1695084736</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>smallcloudai/Refact-1_6B-fim</td>\n",
       "      <td>smallcloudai/Refact-1_6B-fim</td>\n",
       "      <td>2023-08-29 15:48:36+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>28033</td>\n",
       "      <td>129</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 1585842176...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>['bigcode/the-stack-dedup', 'rombodawg/2XUNCEN...</td>\n",
       "      <td>[EvalResult(task_type='text-generation', datas...</td>\n",
       "      <td>...</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['GPTRefactForCausalLM']</td>\n",
       "      <td>['transformers', 'pytorch', 'safetensors', 'gp...</td>\n",
       "      <td>language:\\n- en\\nlicense: bigscience-openrail-...</td>\n",
       "      <td>1585842176</td>\n",
       "      <td>4.252535e-01</td>\n",
       "      <td>1693324116</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>stabilityai/stablecode-completion-alpha-3b-4k</td>\n",
       "      <td>stabilityai/stablecode-completion-alpha-3b-4k</td>\n",
       "      <td>2023-08-07 16:59:19+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1657</td>\n",
       "      <td>284</td>\n",
       "      <td>SafeTensorsInfo(parameters={'F16': 2769311040,...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>['bigcode/starcoderdata']</td>\n",
       "      <td>[EvalResult(task_type='text-generation', datas...</td>\n",
       "      <td>...</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['GPTNeoXForCausalLM']</td>\n",
       "      <td>['transformers', 'pytorch', 'safetensors', 'gp...</td>\n",
       "      <td>language:\\n- code\\nlicense: apache-2.0\\ntags:\\...</td>\n",
       "      <td>3306181952</td>\n",
       "      <td>9.312836e-01</td>\n",
       "      <td>1691427559</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ibm-granite/granite-3.0-1b-a400m-base</td>\n",
       "      <td>ibm-granite/granite-3.0-1b-a400m-base</td>\n",
       "      <td>2024-10-03 21:58:13+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2337</td>\n",
       "      <td>5</td>\n",
       "      <td>SafeTensorsInfo(parameters={'F32': 1384956928}...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[EvalResult(task_type='text-generation', datas...</td>\n",
       "      <td>...</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['GraniteMoeForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'granitemoe', ...</td>\n",
       "      <td>license: apache-2.0\\nlibrary_name: transformer...</td>\n",
       "      <td>1384956928</td>\n",
       "      <td>1.658541e-02</td>\n",
       "      <td>1727992693</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TheBloke/WizardCoder-33B-V1.1-GPTQ</td>\n",
       "      <td>TheBloke/WizardCoder-33B-V1.1-GPTQ</td>\n",
       "      <td>2024-01-04 17:19:01+00:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>SafeTensorsInfo(parameters={'I32': 4114296192,...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[EvalResult(task_type='text-generation', datas...</td>\n",
       "      <td>...</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['LlamaForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'llama', 'text...</td>\n",
       "      <td>library_name: transformers\\ntags:\\n- code\\nbas...</td>\n",
       "      <td>4585296256</td>\n",
       "      <td>3.606755e-02</td>\n",
       "      <td>1704388741</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            model  \\\n",
       "0   TheBloke/speechless-code-mistral-7B-v1.0-GPTQ   \n",
       "1        TheBloke/WizardCoder-Python-13B-V1.0-AWQ   \n",
       "2                 vodkaslime/test-repo-stablecode   \n",
       "3                   TechxGenus/starcoder2-3b-GPTQ   \n",
       "4                   TechxGenus/starcoder2-15b-AWQ   \n",
       "5                nlpguy/granite-3.0-3b-a800m-base   \n",
       "6         TheBloke/WizardCoder-Python-7B-V1.0-AWQ   \n",
       "7                    smallcloudai/Refact-1_6B-fim   \n",
       "8   stabilityai/stablecode-completion-alpha-3b-4k   \n",
       "9           ibm-granite/granite-3.0-1b-a400m-base   \n",
       "10             TheBloke/WizardCoder-33B-V1.1-GPTQ   \n",
       "\n",
       "                                               id                created_at  \\\n",
       "0   TheBloke/speechless-code-mistral-7B-v1.0-GPTQ 2023-10-13 06:08:01+00:00   \n",
       "1        TheBloke/WizardCoder-Python-13B-V1.0-AWQ 2023-09-19 00:53:10+00:00   \n",
       "2                 vodkaslime/test-repo-stablecode 2023-08-23 07:50:01+00:00   \n",
       "3                   TechxGenus/starcoder2-3b-GPTQ 2024-03-22 13:35:25+00:00   \n",
       "4                   TechxGenus/starcoder2-15b-AWQ 2024-04-12 14:03:22+00:00   \n",
       "5                nlpguy/granite-3.0-3b-a800m-base 2024-10-31 14:29:25+00:00   \n",
       "6         TheBloke/WizardCoder-Python-7B-V1.0-AWQ 2023-09-19 00:52:16+00:00   \n",
       "7                    smallcloudai/Refact-1_6B-fim 2023-08-29 15:48:36+00:00   \n",
       "8   stabilityai/stablecode-completion-alpha-3b-4k 2023-08-07 16:59:19+00:00   \n",
       "9           ibm-granite/granite-3.0-1b-a400m-base 2024-10-03 21:58:13+00:00   \n",
       "10             TheBloke/WizardCoder-33B-V1.1-GPTQ 2024-01-04 17:19:01+00:00   \n",
       "\n",
       "   downloads_all_time  downloads  likes  \\\n",
       "0             Unknown         19      2   \n",
       "1             Unknown         22      0   \n",
       "2             Unknown         33      0   \n",
       "3             Unknown        945      1   \n",
       "4             Unknown         28      1   \n",
       "5             Unknown          5      0   \n",
       "6             Unknown        118      2   \n",
       "7             Unknown      28033    129   \n",
       "8             Unknown       1657    284   \n",
       "9             Unknown       2337      5   \n",
       "10            Unknown         24     11   \n",
       "\n",
       "                                          safetensors             task  \\\n",
       "0   SafeTensorsInfo(parameters={'I32': 880476160, ...  text-generation   \n",
       "1   SafeTensorsInfo(parameters={'I32': 1598361600,...  text-generation   \n",
       "2   SafeTensorsInfo(parameters={'BF16': 2769311040...  text-generation   \n",
       "3   SafeTensorsInfo(parameters={'I32': 363432960, ...  text-generation   \n",
       "4   SafeTensorsInfo(parameters={'I32': 1933885440,...  text-generation   \n",
       "5   SafeTensorsInfo(parameters={'F32': 3374286336}...  text-generation   \n",
       "6   SafeTensorsInfo(parameters={'I32': 815824896, ...  text-generation   \n",
       "7   SafeTensorsInfo(parameters={'BF16': 1585842176...  text-generation   \n",
       "8   SafeTensorsInfo(parameters={'F16': 2769311040,...  text-generation   \n",
       "9   SafeTensorsInfo(parameters={'F32': 1384956928}...  text-generation   \n",
       "10  SafeTensorsInfo(parameters={'I32': 4114296192,...  text-generation   \n",
       "\n",
       "                                             datasets  \\\n",
       "0   ['jondurbin/airoboros-2.2', 'Open-Orca/OpenOrc...   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                      ['bigcode/the-stack-v2-train']   \n",
       "4                      ['bigcode/the-stack-v2-train']   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7   ['bigcode/the-stack-dedup', 'rombodawg/2XUNCEN...   \n",
       "8                           ['bigcode/starcoderdata']   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "\n",
       "                                         eval_results  ...  \\\n",
       "0   [EvalResult(task_type='text-generation', datas...  ...   \n",
       "1   [EvalResult(task_type='text-generation', datas...  ...   \n",
       "2   [EvalResult(task_type='text-generation', datas...  ...   \n",
       "3   [EvalResult(task_type='text-generation', datas...  ...   \n",
       "4   [EvalResult(task_type='text-generation', datas...  ...   \n",
       "5   [EvalResult(task_type='text-generation', datas...  ...   \n",
       "6   [EvalResult(task_type='text-generation', datas...  ...   \n",
       "7   [EvalResult(task_type='text-generation', datas...  ...   \n",
       "8   [EvalResult(task_type='text-generation', datas...  ...   \n",
       "9   [EvalResult(task_type='text-generation', datas...  ...   \n",
       "10  [EvalResult(task_type='text-generation', datas...  ...   \n",
       "\n",
       "                                    transformers_info  \\\n",
       "0   TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "1   TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "2   TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "3   TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "4   TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "5   TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "6   TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "7   TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "8   TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "9   TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "10  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "\n",
       "                 architecture  \\\n",
       "0      ['MistralForCausalLM']   \n",
       "1        ['LlamaForCausalLM']   \n",
       "2      ['GPTNeoXForCausalLM']   \n",
       "3   ['Starcoder2ForCausalLM']   \n",
       "4   ['Starcoder2ForCausalLM']   \n",
       "5   ['GraniteMoeForCausalLM']   \n",
       "6        ['LlamaForCausalLM']   \n",
       "7    ['GPTRefactForCausalLM']   \n",
       "8      ['GPTNeoXForCausalLM']   \n",
       "9   ['GraniteMoeForCausalLM']   \n",
       "10       ['LlamaForCausalLM']   \n",
       "\n",
       "                                                 tags  \\\n",
       "0   ['transformers', 'safetensors', 'mistral', 'te...   \n",
       "1   ['transformers', 'safetensors', 'llama', 'text...   \n",
       "2   ['transformers', 'pytorch', 'safetensors', 'gp...   \n",
       "3   ['transformers', 'safetensors', 'starcoder2', ...   \n",
       "4   ['transformers', 'safetensors', 'starcoder2', ...   \n",
       "5   ['transformers', 'safetensors', 'granitemoe', ...   \n",
       "6   ['transformers', 'safetensors', 'llama', 'text...   \n",
       "7   ['transformers', 'pytorch', 'safetensors', 'gp...   \n",
       "8   ['transformers', 'pytorch', 'safetensors', 'gp...   \n",
       "9   ['transformers', 'safetensors', 'granitemoe', ...   \n",
       "10  ['transformers', 'safetensors', 'llama', 'text...   \n",
       "\n",
       "                                            card_data num_parameters  \\\n",
       "0   language:\\n- en\\nlicense: llama2\\nlibrary_name...     1198788608   \n",
       "1   license: llama2\\nlibrary_name: transformers\\nt...     2025589760   \n",
       "2   language:\\n- code\\nlicense: other\\ntags:\\n- ca...     3306181952   \n",
       "3   license: bigcode-openrail-m\\nlibrary_name: tra...      688945152   \n",
       "4   license: bigcode-openrail-m\\nlibrary_name: tra...     2661535744   \n",
       "5   license: apache-2.0\\nlibrary_name: transformer...     3374286336   \n",
       "6   license: llama2\\nlibrary_name: transformers\\nt...     1128837120   \n",
       "7   language:\\n- en\\nlicense: bigscience-openrail-...     1585842176   \n",
       "8   language:\\n- code\\nlicense: apache-2.0\\ntags:\\...     3306181952   \n",
       "9   license: apache-2.0\\nlibrary_name: transformer...     1384956928   \n",
       "10  library_name: transformers\\ntags:\\n- code\\nbas...     4585296256   \n",
       "\n",
       "      popularity  created_at_numeric  popularity_quartile  \\\n",
       "0   6.558938e-03          1697177281                    0   \n",
       "1   1.807119e-06          1695084790                    0   \n",
       "2   2.710678e-06          1692777001                    0   \n",
       "3   3.356312e-03          1711114525                    0   \n",
       "4   3.280988e-03          1712930602                    0   \n",
       "5   4.107089e-07          1730384965                    0   \n",
       "6   6.567070e-03          1695084736                    1   \n",
       "7   4.252535e-01          1693324116                    1   \n",
       "8   9.312836e-01          1691427559                    1   \n",
       "9   1.658541e-02          1727992693                    1   \n",
       "10  3.606755e-02          1704388741                    1   \n",
       "\n",
       "    created_at_quartile  num_parameters_quartile  \n",
       "0                     0                        0  \n",
       "1                     0                        1  \n",
       "2                     0                        2  \n",
       "3                     1                        0  \n",
       "4                     1                        1  \n",
       "5                     1                        2  \n",
       "6                     0                        0  \n",
       "7                     0                        1  \n",
       "8                     0                        2  \n",
       "9                     1                        1  \n",
       "10                    1                        2  \n",
       "\n",
       "[11 rows x 22 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by the quartile columns to create strata\n",
    "strata = df.groupby(['popularity_quartile', 'created_at_quartile', 'num_parameters_quartile'])\n",
    "\n",
    "# Select one model from each stratum\n",
    "selected_models = strata.apply(lambda x: x.sample(1)).reset_index(drop=True)\n",
    "\n",
    "# Display the selected models\n",
    "\n",
    "save_selected_df =True \n",
    "\n",
    "if save_selected_df:\n",
    "    # Optional: Save the filtered DataFrame to a CSV file\n",
    "    selected_models.to_csv(save_dir + \"selected_models_01.csv\", index=False)\n",
    "    print(f\"Filtered CSV file saved: {save_dir}selected_models.csv\")\n",
    "    \n",
    "selected_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:  Series([], Name: id, dtype: object)\n",
      "popularity Quartile: Series([], Name: popularity_quartile, dtype: int64)\n",
      "Created At Quartile: Series([], Name: created_at_quartile, dtype: int64)\n",
      "Num Parameters Quartile: Series([], Name: num_parameters_quartile, dtype: int64)\n",
      "---------------------\n",
      "model:  Series([], Name: id, dtype: object)\n",
      "popularity Quartile: Series([], Name: popularity_quartile, dtype: int64)\n",
      "Created At Quartile: Series([], Name: created_at_quartile, dtype: int64)\n",
      "Num Parameters Quartile: Series([], Name: num_parameters_quartile, dtype: int64)\n",
      "---------------------\n",
      "model:  Series([], Name: id, dtype: object)\n",
      "popularity Quartile: Series([], Name: popularity_quartile, dtype: int64)\n",
      "Created At Quartile: Series([], Name: created_at_quartile, dtype: int64)\n",
      "Num Parameters Quartile: Series([], Name: num_parameters_quartile, dtype: int64)\n",
      "---------------------\n",
      "model:  Series([], Name: id, dtype: object)\n",
      "popularity Quartile: Series([], Name: popularity_quartile, dtype: int64)\n",
      "Created At Quartile: Series([], Name: created_at_quartile, dtype: int64)\n",
      "Num Parameters Quartile: Series([], Name: num_parameters_quartile, dtype: int64)\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "used_models = [\"codeparrot/codeparrot-small\",\n",
    "               \"EleutherAI/pythia-410m\",\n",
    "               \"EleutherAI/pythia-1.4b\",\n",
    "               \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "               \"microsoft/phi-2\"\n",
    "               ]\n",
    "\n",
    "# Assuming 'df' is your DataFrame and you have a specific model ID\n",
    "model_id = used_models[1]  # Replace with the actual model ID\n",
    "\n",
    "for model_id in used_models[1:]: \n",
    "    # Filter the DataFrame to find the model with the given ID\n",
    "    model = df[df['id'] == model_id]\n",
    "    \n",
    "\n",
    "    # Get the quartile values for the selected model\n",
    "    popularity_quartile = model['popularity_quartile']\n",
    "    created_at_quartile = model['created_at_quartile']\n",
    "    num_parameters_quartile = model['num_parameters_quartile']\n",
    "\n",
    "    # Display the quartile values\n",
    "    print(\"model: \", model['id'])\n",
    "    print(\"popularity Quartile:\", popularity_quartile)\n",
    "    print(\"Created At Quartile:\", created_at_quartile)\n",
    "    print(\"Num Parameters Quartile:\", num_parameters_quartile)\n",
    "    print(\"---------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
