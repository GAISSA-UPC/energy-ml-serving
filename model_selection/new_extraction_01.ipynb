{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  first selection\n",
    "\n",
    "- text-generation []\n",
    "- decoder []\n",
    "\n",
    "- open-source models [x]\n",
    "- HF availability [x]\n",
    "- Task: text generation [x]\n",
    "- Date []\n",
    "- architecture: decoder-based only,  []\n",
    "- model size < SLMs size [x]\n",
    "  - https://huggingface.co/docs/accelerate/main/en/usage_guides/model_size_estimator?\n",
    "  - model size from endpoint?\n",
    "  - safetensors -> model_info.safetensors -> https://huggingface.co/microsoft/phi-2 [x]\n",
    "  - check it matches our data about models used []\n",
    "\n",
    "- [?]Code generation [] used in code generation, trained in code datasets?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/fjdur/energy-ml-serving'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"model_selection/\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize API\n",
    "api = HfApi()\n",
    "\n",
    "# Fetch models metadata\n",
    "limit = 20\n",
    "models = api.list_models(task=\"text-generation\", pipeline_tag=\"text-generation\",sort=\"downloads\", limit=limit)\n",
    "#models = api.list_models(task=\"text-generation\", sort=\"downloads\", limit=500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-->\n",
      "model_id: openai-community/gpt2\n",
      "config: {'architectures': ['GPT2LMHeadModel'], 'model_type': 'gpt2', 'tokenizer_config': {}}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ModelInfo' object has no attribute 'downloads_all_time'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m model_info \u001b[38;5;241m=\u001b[39m api\u001b[38;5;241m.\u001b[39mmodel_info(model\u001b[38;5;241m.\u001b[39mmodelId)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_info\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mmodel_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownloads_all_time\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md2: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_info\u001b[38;5;241m.\u001b[39mdownloads\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#print(f'gguf: {model_info.gguf}')\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ModelInfo' object has no attribute 'downloads_all_time'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Filter for decoder-only architectures\n",
    "decoder_models = []\n",
    "i = 0\n",
    "num_models = 200000\n",
    "\n",
    "for model in models:\n",
    "    print(f\"{i}-->\")\n",
    "    if i > num_models:\n",
    "        print(\"breaking\")\n",
    "        break\n",
    "\n",
    "    model_id = getattr(model, \"modelId\", \"Unknown\")\n",
    "    print(f'model_id: {model_id}')\n",
    "\n",
    "    # Fetch detailed model information\n",
    "    model_info = api.model_info(model.modelId)\n",
    "    print(f'config: {model_info.config}')\n",
    "    print(f'd1: {model_info.downloads_all_time}')\n",
    "    print(f'd2: {model_info.downloads}')\n",
    "    #print(f'gguf: {model_info.gguf}')\n",
    "    print(f'safetensors: {model_info.safetensors}')\n",
    "\n",
    "\n",
    "\n",
    "    if model_info.config ==None:\n",
    "        continue\n",
    "\n",
    "    # Collect model metadata with the desired column names\n",
    "    model_metadata = {\n",
    "        #\"model\": model.modelId,  # Model name or ID\n",
    "        \"model\": getattr(model, \"modelId\", \"Unknown\"),\n",
    "\n",
    "        \"id\": getattr(model, \"modelId\", \"Unknown\"),\n",
    "        #\"downloads_all_time\": getattr(model_info, \"downloads_all_time\", \"Unknown\"),\n",
    "        \"downloads\": getattr(model_info, \"downloads\", \"Unknown\"),\n",
    "        \"safetensors\": getattr(model_info, \"safetensors\", \"Unknown\"),\n",
    "\n",
    "        \"tags\": getattr(model, \"tags\", \"Unknown\"),\n",
    "        \"task\": getattr(model_info, \"pipeline_tag\", \"Unknown\"),\n",
    "        \"card_data\": getattr(model_info, \"card_data\", \"Unknown\"),\n",
    "        \"created_at\": getattr(model, \"created_at\", \"Unknown\"),\n",
    "        \"library_name\": getattr(model, \"library_name\", \"Unknown\"),\n",
    "        \"transformers_info\": getattr(model_info, \"transformers_info\", \"Unknown\"),\n",
    "        \"architecture\": model_info.config.get(\"architectures\", \"Unknown\")\n",
    "    }\n",
    "    print(f'model_metadata: {model_metadata}')\n",
    "\n",
    "    decoder_models.append(model_metadata)\n",
    "    i += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key 'safetensors' in item at index 5 has a value of None.\n",
      "Key 'safetensors' in item at index 6 has a value of None.\n"
     ]
    }
   ],
   "source": [
    "# Check for inconsistencies\n",
    "for index, item in enumerate(decoder_models):\n",
    "    if not isinstance(item, dict):\n",
    "        print(f\"Item at index {index} is not a dictionary: {item}\")\n",
    "    else:\n",
    "        # Check for problematic keys or data\n",
    "        for key, value in item.items():\n",
    "            if value is None:\n",
    "                print(f\"Key '{key}' in item at index {index} has a value of None.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame created successfully\n"
     ]
    }
   ],
   "source": [
    "# Attempt to create the DataFrame in a simplified way\n",
    "try:\n",
    "    df = pd.DataFrame(decoder_models)\n",
    "    print(\"DataFrame created successfully\")\n",
    "    #print(df.head())  # Display only the first few rows to avoid rendering issues\n",
    "except Exception as e:\n",
    "    print(f\"Error creating DataFrame: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved: decoder_models.csv\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"decoder_models.csv\", index=False)\n",
    "print(\"CSV file saved: decoder_models.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['model', 'id', 'downloads', 'safetensors', 'tags', 'task', 'created_at',\n",
       "       'library_name', 'transformers_info', 'architecture'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2024-09-17 14:10:29+00:00\n",
       "1    2022-03-02 23:29:04+00:00\n",
       "2    2024-07-16 01:29:54+00:00\n",
       "3    2024-07-16 08:07:29+00:00\n",
       "4    2022-10-08 16:14:42+00:00\n",
       "5    2022-05-11 08:25:17+00:00\n",
       "6    2024-07-18 08:56:00+00:00\n",
       "7    2022-03-02 23:29:04+00:00\n",
       "8    2024-07-16 16:07:46+00:00\n",
       "9    2024-04-17 09:35:12+00:00\n",
       "10   2023-02-08 15:12:33+00:00\n",
       "11   2023-03-29 07:11:13+00:00\n",
       "12   2024-09-18 15:12:47+00:00\n",
       "13   2024-07-04 10:15:41+00:00\n",
       "14   2023-07-13 16:16:13+00:00\n",
       "15   2024-09-18 15:03:14+00:00\n",
       "16   2023-12-30 06:27:30+00:00\n",
       "17   2024-10-22 15:44:28+00:00\n",
       "18   2023-06-17 19:52:11+00:00\n",
       "19   2022-03-02 23:29:04+00:00\n",
       "Name: created_at, dtype: datetime64[ns, UTC]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['created_at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total models: 139013\n"
     ]
    }
   ],
   "source": [
    "file_name = 'model_selection/results/decoder_models_info_01.csv'\n",
    "df = pd.read_csv(file_name)\n",
    "print(f'total models: {len(df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SafeTensorsInfo(parameters={'BF16': 1711376384}, total=1711376384)\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]['safetensors']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84420\n"
     ]
    }
   ],
   "source": [
    "# Filter out rows where the 'safetensors' column is NaN\n",
    "filtered_df = df[df['safetensors'].notna()]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(len(filtered_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5622/1210555001.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['num_parameters'] = filtered_df['safetensors'].apply(extract_total)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>downloads_all_time</th>\n",
       "      <th>downloads</th>\n",
       "      <th>safetensors</th>\n",
       "      <th>task</th>\n",
       "      <th>library_name</th>\n",
       "      <th>transformers_info</th>\n",
       "      <th>architecture</th>\n",
       "      <th>tags</th>\n",
       "      <th>num_parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HuggingFaceTB/SmolLM2-1.7B-Instruct</td>\n",
       "      <td>HuggingFaceTB/SmolLM2-1.7B-Instruct</td>\n",
       "      <td>2024-10-31 13:42:06+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5369</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 1711376384...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['LlamaForCausalLM']</td>\n",
       "      <td>['transformers', 'tensorboard', 'onnx', 'safet...</td>\n",
       "      <td>1711376384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nvidia/Llama-3.1-Nemotron-70B-Instruct-HF</td>\n",
       "      <td>nvidia/Llama-3.1-Nemotron-70B-Instruct-HF</td>\n",
       "      <td>2024-10-12 02:37:13+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167648</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 7055370649...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['LlamaForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'llama', 'text...</td>\n",
       "      <td>70553706496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meta-llama/Llama-3.2-1B</td>\n",
       "      <td>meta-llama/Llama-3.2-1B</td>\n",
       "      <td>2024-09-18 15:03:14+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1171141</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 1235814400...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['LlamaForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'llama', 'text...</td>\n",
       "      <td>1235814400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>facebook/MobileLLM-1B</td>\n",
       "      <td>facebook/MobileLLM-1B</td>\n",
       "      <td>2024-10-31 00:07:47+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1837</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 1046421760...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['MobileLLMForCausalLM']</td>\n",
       "      <td>['transformers', 'pytorch', 'safetensors', 'mo...</td>\n",
       "      <td>1046421760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CohereForAI/aya-expanse-8b</td>\n",
       "      <td>CohereForAI/aya-expanse-8b</td>\n",
       "      <td>2024-10-23 06:34:13+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14698</td>\n",
       "      <td>SafeTensorsInfo(parameters={'F16': 8028033024}...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['CohereForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'cohere', 'tex...</td>\n",
       "      <td>8028033024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       model  \\\n",
       "0        HuggingFaceTB/SmolLM2-1.7B-Instruct   \n",
       "1  nvidia/Llama-3.1-Nemotron-70B-Instruct-HF   \n",
       "2                    meta-llama/Llama-3.2-1B   \n",
       "3                      facebook/MobileLLM-1B   \n",
       "4                 CohereForAI/aya-expanse-8b   \n",
       "\n",
       "                                          id                 created_at  \\\n",
       "0        HuggingFaceTB/SmolLM2-1.7B-Instruct  2024-10-31 13:42:06+00:00   \n",
       "1  nvidia/Llama-3.1-Nemotron-70B-Instruct-HF  2024-10-12 02:37:13+00:00   \n",
       "2                    meta-llama/Llama-3.2-1B  2024-09-18 15:03:14+00:00   \n",
       "3                      facebook/MobileLLM-1B  2024-10-31 00:07:47+00:00   \n",
       "4                 CohereForAI/aya-expanse-8b  2024-10-23 06:34:13+00:00   \n",
       "\n",
       "   downloads_all_time  downloads  \\\n",
       "0                 NaN       5369   \n",
       "1                 NaN     167648   \n",
       "2                 NaN    1171141   \n",
       "3                 NaN       1837   \n",
       "4                 NaN      14698   \n",
       "\n",
       "                                         safetensors             task  \\\n",
       "0  SafeTensorsInfo(parameters={'BF16': 1711376384...  text-generation   \n",
       "1  SafeTensorsInfo(parameters={'BF16': 7055370649...  text-generation   \n",
       "2  SafeTensorsInfo(parameters={'BF16': 1235814400...  text-generation   \n",
       "3  SafeTensorsInfo(parameters={'BF16': 1046421760...  text-generation   \n",
       "4  SafeTensorsInfo(parameters={'F16': 8028033024}...  text-generation   \n",
       "\n",
       "   library_name                                  transformers_info  \\\n",
       "0  transformers  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "1  transformers  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "2  transformers  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "3  transformers  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "4  transformers  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "\n",
       "               architecture  \\\n",
       "0      ['LlamaForCausalLM']   \n",
       "1      ['LlamaForCausalLM']   \n",
       "2      ['LlamaForCausalLM']   \n",
       "3  ['MobileLLMForCausalLM']   \n",
       "4     ['CohereForCausalLM']   \n",
       "\n",
       "                                                tags  num_parameters  \n",
       "0  ['transformers', 'tensorboard', 'onnx', 'safet...      1711376384  \n",
       "1  ['transformers', 'safetensors', 'llama', 'text...     70553706496  \n",
       "2  ['transformers', 'safetensors', 'llama', 'text...      1235814400  \n",
       "3  ['transformers', 'pytorch', 'safetensors', 'mo...      1046421760  \n",
       "4  ['transformers', 'safetensors', 'cohere', 'tex...      8028033024  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to extract the 'total' value from the 'safetensors' string\n",
    "def extract_total(safetensors_info):\n",
    "    if pd.isna(safetensors_info):\n",
    "        return None\n",
    "    match = re.search(r\"total=(\\d+)\", safetensors_info)\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "# Create a new column 'num_parameters' with the extracted total\n",
    "filtered_df['num_parameters'] = filtered_df['safetensors'].apply(extract_total)\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5622/2593281030.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['created_at'] = pd.to_datetime(filtered_df['created_at'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "filtered_df['created_at'] = pd.to_datetime(filtered_df['created_at'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered w/ created_at len now:84420\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'decoder_models' is already populated with the model metadata\n",
    "#df = pd.DataFrame(decoder_models)\n",
    "\n",
    "# Convert 'created_at' to datetime format, handling possible parsing errors\n",
    "#df['created_at'] = pd.to_datetime(df['created_at'], errors='coerce')\n",
    "\n",
    "# Filter models with 'created_at' in 2023 or later\n",
    "year = 2021\n",
    "filtered_df = filtered_df[filtered_df['created_at'].dt.year >= year]\n",
    "\n",
    "print(f\"filtered w/ created_at len now:{len(filtered_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43445\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>downloads_all_time</th>\n",
       "      <th>downloads</th>\n",
       "      <th>safetensors</th>\n",
       "      <th>task</th>\n",
       "      <th>library_name</th>\n",
       "      <th>transformers_info</th>\n",
       "      <th>architecture</th>\n",
       "      <th>tags</th>\n",
       "      <th>num_parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HuggingFaceTB/SmolLM2-1.7B-Instruct</td>\n",
       "      <td>HuggingFaceTB/SmolLM2-1.7B-Instruct</td>\n",
       "      <td>2024-10-31 13:42:06+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5369</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 1711376384...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['LlamaForCausalLM']</td>\n",
       "      <td>['transformers', 'tensorboard', 'onnx', 'safet...</td>\n",
       "      <td>1711376384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meta-llama/Llama-3.2-1B</td>\n",
       "      <td>meta-llama/Llama-3.2-1B</td>\n",
       "      <td>2024-09-18 15:03:14+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1171141</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 1235814400...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['LlamaForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'llama', 'text...</td>\n",
       "      <td>1235814400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>facebook/MobileLLM-1B</td>\n",
       "      <td>facebook/MobileLLM-1B</td>\n",
       "      <td>2024-10-31 00:07:47+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1837</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 1046421760...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['MobileLLMForCausalLM']</td>\n",
       "      <td>['transformers', 'pytorch', 'safetensors', 'mo...</td>\n",
       "      <td>1046421760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>meta-llama/Llama-3.2-3B-Instruct</td>\n",
       "      <td>meta-llama/Llama-3.2-3B-Instruct</td>\n",
       "      <td>2024-09-18 15:19:20+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>992933</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 3212749824...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['LlamaForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'llama', 'text...</td>\n",
       "      <td>3212749824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>facebook/MobileLLM-125M</td>\n",
       "      <td>facebook/MobileLLM-125M</td>\n",
       "      <td>2024-10-30 22:48:34+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2048</td>\n",
       "      <td>SafeTensorsInfo(parameters={'F16': 124635456},...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['MobileLLMForCausalLM']</td>\n",
       "      <td>['transformers', 'pytorch', 'safetensors', 'mo...</td>\n",
       "      <td>124635456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model                                   id  \\\n",
       "0  HuggingFaceTB/SmolLM2-1.7B-Instruct  HuggingFaceTB/SmolLM2-1.7B-Instruct   \n",
       "2              meta-llama/Llama-3.2-1B              meta-llama/Llama-3.2-1B   \n",
       "3                facebook/MobileLLM-1B                facebook/MobileLLM-1B   \n",
       "6     meta-llama/Llama-3.2-3B-Instruct     meta-llama/Llama-3.2-3B-Instruct   \n",
       "8              facebook/MobileLLM-125M              facebook/MobileLLM-125M   \n",
       "\n",
       "                 created_at  downloads_all_time  downloads  \\\n",
       "0 2024-10-31 13:42:06+00:00                 NaN       5369   \n",
       "2 2024-09-18 15:03:14+00:00                 NaN    1171141   \n",
       "3 2024-10-31 00:07:47+00:00                 NaN       1837   \n",
       "6 2024-09-18 15:19:20+00:00                 NaN     992933   \n",
       "8 2024-10-30 22:48:34+00:00                 NaN       2048   \n",
       "\n",
       "                                         safetensors             task  \\\n",
       "0  SafeTensorsInfo(parameters={'BF16': 1711376384...  text-generation   \n",
       "2  SafeTensorsInfo(parameters={'BF16': 1235814400...  text-generation   \n",
       "3  SafeTensorsInfo(parameters={'BF16': 1046421760...  text-generation   \n",
       "6  SafeTensorsInfo(parameters={'BF16': 3212749824...  text-generation   \n",
       "8  SafeTensorsInfo(parameters={'F16': 124635456},...  text-generation   \n",
       "\n",
       "   library_name                                  transformers_info  \\\n",
       "0  transformers  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "2  transformers  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "3  transformers  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "6  transformers  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "8  transformers  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "\n",
       "               architecture  \\\n",
       "0      ['LlamaForCausalLM']   \n",
       "2      ['LlamaForCausalLM']   \n",
       "3  ['MobileLLMForCausalLM']   \n",
       "6      ['LlamaForCausalLM']   \n",
       "8  ['MobileLLMForCausalLM']   \n",
       "\n",
       "                                                tags  num_parameters  \n",
       "0  ['transformers', 'tensorboard', 'onnx', 'safet...      1711376384  \n",
       "2  ['transformers', 'safetensors', 'llama', 'text...      1235814400  \n",
       "3  ['transformers', 'pytorch', 'safetensors', 'mo...      1046421760  \n",
       "6  ['transformers', 'safetensors', 'llama', 'text...      3212749824  \n",
       "8  ['transformers', 'pytorch', 'safetensors', 'mo...       124635456  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out rows where the 'safetensors' column is NaN\n",
    "limit_slm_parameters=5000000000 # 10B\n",
    "filtered_df = filtered_df[filtered_df['num_parameters'] <= limit_slm_parameters]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(len(filtered_df))\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered CSV file saved: filtered_models.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "save_filtered_df =True\n",
    "if save_filtered_df:\n",
    "    # Optional: Save the filtered DataFrame to a CSV file\n",
    "    filtered_df.to_csv(\"results/filtered_models.csv\", index=False)\n",
    "    print(\"Filtered CSV file saved: filtered_models.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15329\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model                                           mehdirafiei/SQLCODER7B2\n",
       "id                                              mehdirafiei/SQLCODER7B2\n",
       "created_at                                    2024-02-17 11:08:37+00:00\n",
       "downloads_all_time                                                  NaN\n",
       "downloads                                                            12\n",
       "safetensors           SafeTensorsInfo(parameters={'BF16': 6738546688...\n",
       "task                                                    text-generation\n",
       "library_name                                               transformers\n",
       "transformers_info     TransformersInfo(auto_model='AutoModelForCausa...\n",
       "architecture                                       ['LlamaForCausalLM']\n",
       "tags                  ['transformers', 'safetensors', 'llama', 'text...\n",
       "num_parameters                                               6738546688\n",
       "Name: 54760, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stratification criteria\n",
    "import random\n",
    "i = random.randint(0,len(filtered_df))\n",
    "print(i)\n",
    "row = filtered_df.iloc[i]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stratified sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total models: 76437\n"
     ]
    }
   ],
   "source": [
    "file_name = 'results/filtered_models.csv'\n",
    "df = pd.read_csv(file_name)\n",
    "print(f'total models: {len(df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['model', 'id', 'created_at', 'downloads_all_time', 'downloads',\n",
       "       'safetensors', 'task', 'library_name', 'transformers_info',\n",
       "       'architecture', 'tags', 'num_parameters'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add likes: popularity = sum of the normalized likes and downloads\n",
    "stratification_criteria = ['downloads', 'num_parameters','created_at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   downloads_quartile  created_at_quartile  num_parameters_quartile\n",
      "0                   1                    1                        1\n",
      "1                   1                    1                        0\n",
      "2                   1                    1                        0\n",
      "3                   1                    1                        2\n",
      "4                   1                    1                        2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have loaded your DataFrame 'df'\n",
    "\n",
    "# Convert 'created_at' to a numerical format for quartile calculation\n",
    "df['created_at'] = pd.to_datetime(df['created_at'], errors='coerce')\n",
    "df['created_at_numeric'] = df['created_at'].astype(int) // 10**9  # Convert to Unix timestamp, seconds\n",
    "\n",
    "# Create quartiles for stratified sampling\n",
    "df['downloads_quartile'] = pd.qcut(df['downloads'], q=2, labels=False)  # 2 quartiles\n",
    "df['created_at_quartile'] = pd.qcut(df['created_at_numeric'], q=2, labels=False)  # 2 quartiles\n",
    "df['num_parameters_quartile'] = pd.qcut(df['num_parameters'], q=3, labels=False)  # 3 quartiles\n",
    "\n",
    "# Display the DataFrame with new quartile columns\n",
    "print(df[['downloads_quartile', 'created_at_quartile', 'num_parameters_quartile']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5622/497035949.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  selected_models = strata.apply(lambda x: x.sample(1)).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>downloads_all_time</th>\n",
       "      <th>downloads</th>\n",
       "      <th>safetensors</th>\n",
       "      <th>task</th>\n",
       "      <th>library_name</th>\n",
       "      <th>transformers_info</th>\n",
       "      <th>architecture</th>\n",
       "      <th>tags</th>\n",
       "      <th>num_parameters</th>\n",
       "      <th>created_at_numeric</th>\n",
       "      <th>downloads_quartile</th>\n",
       "      <th>created_at_quartile</th>\n",
       "      <th>num_parameters_quartile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FounderOfHuggingface/fresh_gpt2_gen_full_dbped...</td>\n",
       "      <td>FounderOfHuggingface/fresh_gpt2_gen_full_dbped...</td>\n",
       "      <td>2024-01-12 09:12:57+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>SafeTensorsInfo(parameters={'F32': 124439808},...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['GPT2LMHeadModel']</td>\n",
       "      <td>['transformers', 'safetensors', 'gpt2', 'text-...</td>\n",
       "      <td>124439808</td>\n",
       "      <td>1705050777</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ura-hcmut/MixSUra-AWQ</td>\n",
       "      <td>ura-hcmut/MixSUra-AWQ</td>\n",
       "      <td>2024-01-03 16:44:34+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>SafeTensorsInfo(parameters={'I32': 5850267648,...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['MixtralForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'mixtral', 'te...</td>\n",
       "      <td>6476533760</td>\n",
       "      <td>1704300274</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>danwils/BatakToba-Seallm-7B-v2</td>\n",
       "      <td>danwils/BatakToba-Seallm-7B-v2</td>\n",
       "      <td>2024-02-24 15:30:14+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 7375949824...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['MistralForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'mistral', 'te...</td>\n",
       "      <td>7375949824</td>\n",
       "      <td>1708788614</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mlx-community/1.5-Pints-16K-v0.1</td>\n",
       "      <td>mlx-community/1.5-Pints-16K-v0.1</td>\n",
       "      <td>2024-10-28 17:23:19+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>SafeTensorsInfo(parameters={'F16': 1565886464}...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>mlx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['LlamaForCausalLM']</td>\n",
       "      <td>['mlx', 'safetensors', 'llama', 'text-generati...</td>\n",
       "      <td>1565886464</td>\n",
       "      <td>1730136199</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mursel/mistral_7bv03-tr-qlora</td>\n",
       "      <td>Mursel/mistral_7bv03-tr-qlora</td>\n",
       "      <td>2024-07-22 13:21:56+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>SafeTensorsInfo(parameters={'F32': 151264768, ...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['MistralForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'mistral', 'te...</td>\n",
       "      <td>3909379392</td>\n",
       "      <td>1721654516</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mergekit-community/mergekit-slerp-vysthui</td>\n",
       "      <td>mergekit-community/mergekit-slerp-vysthui</td>\n",
       "      <td>2024-07-04 22:11:01+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>SafeTensorsInfo(parameters={'BF16': 7241732096...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['MistralForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'mistral', 'te...</td>\n",
       "      <td>7241732096</td>\n",
       "      <td>1720131061</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>berquetR/phi_first_train</td>\n",
       "      <td>berquetR/phi_first_train</td>\n",
       "      <td>2024-04-24 13:13:43+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>SafeTensorsInfo(parameters={'F32': 18876672, '...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['PhiForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'phi', 'text-g...</td>\n",
       "      <td>833179280</td>\n",
       "      <td>1713964423</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TheBloke/Frostwind-10.7B-v1-GPTQ</td>\n",
       "      <td>TheBloke/Frostwind-10.7B-v1-GPTQ</td>\n",
       "      <td>2023-12-20 08:13:21+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>SafeTensorsInfo(parameters={'I32': 1320714240,...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['LlamaForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'llama', 'text...</td>\n",
       "      <td>1667108864</td>\n",
       "      <td>1703060001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TheBloke/meditron-70B-GPTQ</td>\n",
       "      <td>TheBloke/meditron-70B-GPTQ</td>\n",
       "      <td>2023-11-30 17:10:33+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>SafeTensorsInfo(parameters={'I32': 8563445760,...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['LlamaForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'llama', 'text...</td>\n",
       "      <td>9102487552</td>\n",
       "      <td>1701364233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KANISHKVIJAY/gpt2_interview_model</td>\n",
       "      <td>KANISHKVIJAY/gpt2_interview_model</td>\n",
       "      <td>2024-06-16 12:46:56+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>SafeTensorsInfo(parameters={'F32': 124439808},...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['GPT2LMHeadModel']</td>\n",
       "      <td>['transformers', 'safetensors', 'gpt2', 'text-...</td>\n",
       "      <td>124439808</td>\n",
       "      <td>1718542016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PrunaAI/beomi-Llama-3-KoEn-8B-Instruct-preview...</td>\n",
       "      <td>PrunaAI/beomi-Llama-3-KoEn-8B-Instruct-preview...</td>\n",
       "      <td>2024-06-24 08:58:07+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>SafeTensorsInfo(parameters={'I32': 879230976, ...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['LlamaForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'llama', 'text...</td>\n",
       "      <td>1984696320</td>\n",
       "      <td>1719219487</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KSU-HW-SEC/Power_Area_Time_SFT</td>\n",
       "      <td>KSU-HW-SEC/Power_Area_Time_SFT</td>\n",
       "      <td>2024-10-11 07:03:13+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>SafeTensorsInfo(parameters={'F16': 7241740288}...</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>transformers</td>\n",
       "      <td>TransformersInfo(auto_model='AutoModelForCausa...</td>\n",
       "      <td>['MistralForCausalLM']</td>\n",
       "      <td>['transformers', 'safetensors', 'mistral', 'te...</td>\n",
       "      <td>7241740288</td>\n",
       "      <td>1728630193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                model  \\\n",
       "0   FounderOfHuggingface/fresh_gpt2_gen_full_dbped...   \n",
       "1                               ura-hcmut/MixSUra-AWQ   \n",
       "2                      danwils/BatakToba-Seallm-7B-v2   \n",
       "3                    mlx-community/1.5-Pints-16K-v0.1   \n",
       "4                       Mursel/mistral_7bv03-tr-qlora   \n",
       "5           mergekit-community/mergekit-slerp-vysthui   \n",
       "6                            berquetR/phi_first_train   \n",
       "7                    TheBloke/Frostwind-10.7B-v1-GPTQ   \n",
       "8                          TheBloke/meditron-70B-GPTQ   \n",
       "9                   KANISHKVIJAY/gpt2_interview_model   \n",
       "10  PrunaAI/beomi-Llama-3-KoEn-8B-Instruct-preview...   \n",
       "11                     KSU-HW-SEC/Power_Area_Time_SFT   \n",
       "\n",
       "                                                   id  \\\n",
       "0   FounderOfHuggingface/fresh_gpt2_gen_full_dbped...   \n",
       "1                               ura-hcmut/MixSUra-AWQ   \n",
       "2                      danwils/BatakToba-Seallm-7B-v2   \n",
       "3                    mlx-community/1.5-Pints-16K-v0.1   \n",
       "4                       Mursel/mistral_7bv03-tr-qlora   \n",
       "5           mergekit-community/mergekit-slerp-vysthui   \n",
       "6                            berquetR/phi_first_train   \n",
       "7                    TheBloke/Frostwind-10.7B-v1-GPTQ   \n",
       "8                          TheBloke/meditron-70B-GPTQ   \n",
       "9                   KANISHKVIJAY/gpt2_interview_model   \n",
       "10  PrunaAI/beomi-Llama-3-KoEn-8B-Instruct-preview...   \n",
       "11                     KSU-HW-SEC/Power_Area_Time_SFT   \n",
       "\n",
       "                  created_at  downloads_all_time  downloads  \\\n",
       "0  2024-01-12 09:12:57+00:00                 NaN          4   \n",
       "1  2024-01-03 16:44:34+00:00                 NaN          0   \n",
       "2  2024-02-24 15:30:14+00:00                 NaN          2   \n",
       "3  2024-10-28 17:23:19+00:00                 NaN          7   \n",
       "4  2024-07-22 13:21:56+00:00                 NaN          7   \n",
       "5  2024-07-04 22:11:01+00:00                 NaN          7   \n",
       "6  2024-04-24 13:13:43+00:00                 NaN         16   \n",
       "7  2023-12-20 08:13:21+00:00                 NaN         13   \n",
       "8  2023-11-30 17:10:33+00:00                 NaN         22   \n",
       "9  2024-06-16 12:46:56+00:00                 NaN         11   \n",
       "10 2024-06-24 08:58:07+00:00                 NaN         11   \n",
       "11 2024-10-11 07:03:13+00:00                 NaN         18   \n",
       "\n",
       "                                          safetensors             task  \\\n",
       "0   SafeTensorsInfo(parameters={'F32': 124439808},...  text-generation   \n",
       "1   SafeTensorsInfo(parameters={'I32': 5850267648,...  text-generation   \n",
       "2   SafeTensorsInfo(parameters={'BF16': 7375949824...  text-generation   \n",
       "3   SafeTensorsInfo(parameters={'F16': 1565886464}...  text-generation   \n",
       "4   SafeTensorsInfo(parameters={'F32': 151264768, ...  text-generation   \n",
       "5   SafeTensorsInfo(parameters={'BF16': 7241732096...  text-generation   \n",
       "6   SafeTensorsInfo(parameters={'F32': 18876672, '...  text-generation   \n",
       "7   SafeTensorsInfo(parameters={'I32': 1320714240,...  text-generation   \n",
       "8   SafeTensorsInfo(parameters={'I32': 8563445760,...  text-generation   \n",
       "9   SafeTensorsInfo(parameters={'F32': 124439808},...  text-generation   \n",
       "10  SafeTensorsInfo(parameters={'I32': 879230976, ...  text-generation   \n",
       "11  SafeTensorsInfo(parameters={'F16': 7241740288}...  text-generation   \n",
       "\n",
       "    library_name                                  transformers_info  \\\n",
       "0   transformers  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "1   transformers  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "2   transformers  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "3            mlx                                                NaN   \n",
       "4   transformers  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "5   transformers  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "6   transformers  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "7   transformers  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "8   transformers  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "9   transformers  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "10  transformers  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "11  transformers  TransformersInfo(auto_model='AutoModelForCausa...   \n",
       "\n",
       "              architecture                                               tags  \\\n",
       "0      ['GPT2LMHeadModel']  ['transformers', 'safetensors', 'gpt2', 'text-...   \n",
       "1   ['MixtralForCausalLM']  ['transformers', 'safetensors', 'mixtral', 'te...   \n",
       "2   ['MistralForCausalLM']  ['transformers', 'safetensors', 'mistral', 'te...   \n",
       "3     ['LlamaForCausalLM']  ['mlx', 'safetensors', 'llama', 'text-generati...   \n",
       "4   ['MistralForCausalLM']  ['transformers', 'safetensors', 'mistral', 'te...   \n",
       "5   ['MistralForCausalLM']  ['transformers', 'safetensors', 'mistral', 'te...   \n",
       "6       ['PhiForCausalLM']  ['transformers', 'safetensors', 'phi', 'text-g...   \n",
       "7     ['LlamaForCausalLM']  ['transformers', 'safetensors', 'llama', 'text...   \n",
       "8     ['LlamaForCausalLM']  ['transformers', 'safetensors', 'llama', 'text...   \n",
       "9      ['GPT2LMHeadModel']  ['transformers', 'safetensors', 'gpt2', 'text-...   \n",
       "10    ['LlamaForCausalLM']  ['transformers', 'safetensors', 'llama', 'text...   \n",
       "11  ['MistralForCausalLM']  ['transformers', 'safetensors', 'mistral', 'te...   \n",
       "\n",
       "    num_parameters  created_at_numeric  downloads_quartile  \\\n",
       "0        124439808          1705050777                   0   \n",
       "1       6476533760          1704300274                   0   \n",
       "2       7375949824          1708788614                   0   \n",
       "3       1565886464          1730136199                   0   \n",
       "4       3909379392          1721654516                   0   \n",
       "5       7241732096          1720131061                   0   \n",
       "6        833179280          1713964423                   1   \n",
       "7       1667108864          1703060001                   1   \n",
       "8       9102487552          1701364233                   1   \n",
       "9        124439808          1718542016                   1   \n",
       "10      1984696320          1719219487                   1   \n",
       "11      7241740288          1728630193                   1   \n",
       "\n",
       "    created_at_quartile  num_parameters_quartile  \n",
       "0                     0                        0  \n",
       "1                     0                        1  \n",
       "2                     0                        2  \n",
       "3                     1                        0  \n",
       "4                     1                        1  \n",
       "5                     1                        2  \n",
       "6                     0                        0  \n",
       "7                     0                        1  \n",
       "8                     0                        2  \n",
       "9                     1                        0  \n",
       "10                    1                        1  \n",
       "11                    1                        2  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by the quartile columns to create strata\n",
    "strata = df.groupby(['downloads_quartile', 'created_at_quartile', 'num_parameters_quartile'])\n",
    "\n",
    "# Select one model from each stratum\n",
    "selected_models = strata.apply(lambda x: x.sample(1)).reset_index(drop=True)\n",
    "\n",
    "# Display the selected models\n",
    "selected_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:  1744    EleutherAI/pythia-410m\n",
      "Name: id, dtype: object\n",
      "Downloads Quartile: 1744    1\n",
      "Name: downloads_quartile, dtype: int64\n",
      "Created At Quartile: 1744    0\n",
      "Name: created_at_quartile, dtype: int64\n",
      "Num Parameters Quartile: 1744    0\n",
      "Name: num_parameters_quartile, dtype: int64\n",
      "---------------------\n",
      "model:  208    EleutherAI/pythia-1.4b\n",
      "Name: id, dtype: object\n",
      "Downloads Quartile: 208    1\n",
      "Name: downloads_quartile, dtype: int64\n",
      "Created At Quartile: 208    0\n",
      "Name: created_at_quartile, dtype: int64\n",
      "Num Parameters Quartile: 208    0\n",
      "Name: num_parameters_quartile, dtype: int64\n",
      "---------------------\n",
      "model:  368    TinyLlama/TinyLlama-1.1B-Chat-v1.0\n",
      "Name: id, dtype: object\n",
      "Downloads Quartile: 368    1\n",
      "Name: downloads_quartile, dtype: int64\n",
      "Created At Quartile: 368    0\n",
      "Name: created_at_quartile, dtype: int64\n",
      "Num Parameters Quartile: 368    0\n",
      "Name: num_parameters_quartile, dtype: int64\n",
      "---------------------\n",
      "model:  350    microsoft/phi-2\n",
      "Name: id, dtype: object\n",
      "Downloads Quartile: 350    1\n",
      "Name: downloads_quartile, dtype: int64\n",
      "Created At Quartile: 350    0\n",
      "Name: created_at_quartile, dtype: int64\n",
      "Num Parameters Quartile: 350    1\n",
      "Name: num_parameters_quartile, dtype: int64\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "used_models = [\"codeparrot/codeparrot-small\",\n",
    "               \"EleutherAI/pythia-410m\",\n",
    "               \"EleutherAI/pythia-1.4b\",\n",
    "               \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "               \"microsoft/phi-2\"\n",
    "               ]\n",
    "\n",
    "# Assuming 'df' is your DataFrame and you have a specific model ID\n",
    "model_id = used_models[1]  # Replace with the actual model ID\n",
    "\n",
    "for model_id in used_models[1:]: \n",
    "    # Filter the DataFrame to find the model with the given ID\n",
    "    model = df[df['id'] == model_id]\n",
    "\n",
    "    # Get the quartile values for the selected model\n",
    "    downloads_quartile = model['downloads_quartile']\n",
    "    created_at_quartile = model['created_at_quartile']\n",
    "    num_parameters_quartile = model['num_parameters_quartile']\n",
    "\n",
    "    # Display the quartile values\n",
    "    print(\"model: \", model['id'])\n",
    "    print(\"Downloads Quartile:\", downloads_quartile)\n",
    "    print(\"Created At Quartile:\", created_at_quartile)\n",
    "    print(\"Num Parameters Quartile:\", num_parameters_quartile)\n",
    "    print(\"---------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
