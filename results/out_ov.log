None
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

INFRASTRUCTURE -> ov

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Running experiment infrastructure -> ov, model -> codet5-base, dataset -> testing/inputs.txt, reps -> 1

------------------------------

---------------- Rep 1 out of 1: 

Running POST requests infrastructure -> ov, model -> codet5-base, dataset -> testing/inputs.txt

Dataset: ['def hello_world():', 'for i in range(10):', 'print("Hello, world!")', 'if x > 5:']
---
Running POST requests infrastructure -> ov, model -> codet5-base, dataset -> ['def hello_world():', 'for i in range(10):', 'print("Hello, world!")', 'if x > 5:']

___________________________________
Endpoint: http://localhost:8000/huggingface_models/codet5-base/ov
None
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

INFRASTRUCTURE -> ov

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Running experiment infrastructure -> ov, model -> codet5-base, dataset -> testing/inputs.txt, reps -> 1

------------------------------

---------------- Rep 1 out of 1: 

Running POST requests infrastructure -> ov, model -> codet5-base, dataset -> testing/inputs.txt

Dataset: ['def hello_world():', 'for i in range(10):', 'print("Hello, world!")', 'if x > 5:']
---
Running POST requests infrastructure -> ov, model -> codet5-base, dataset -> ['def hello_world():', 'for i in range(10):', 'print("Hello, world!")', 'if x > 5:']

___________________________________
Endpoint: http://localhost:8000/huggingface_models/codet5-base/ov
{'message': 'OK', 'method': 'POST', 'status-code': 200, 'timestamp': '2023-12-13T00:47:02.910062', 'url': 'http://localhost:8000/huggingface_models/codet5-base/ov', 'data': {'model-type': 'Codet5_base', 'input_text': 'def hello_world():', 'prediction': {'prediction': 'def hello_world(self, message) : self.hello_world(message'}}}
Inference successful!
{'prediction': 'def hello_world(self, message) : self.hello_world(message'}
___________________________________
Endpoint: http://localhost:8000/huggingface_models/codet5-base/ov
{'message': 'OK', 'method': 'POST', 'status-code': 200, 'timestamp': '2023-12-13T00:47:10.965769', 'url': 'http://localhost:8000/huggingface_models/codet5-base/ov', 'data': {'model-type': 'Codet5_base', 'input_text': 'for i in range(10):', 'prediction': {'prediction': 't h i s.'}}}
Inference successful!
{'prediction': 't h i s.'}
___________________________________
Endpoint: http://localhost:8000/huggingface_models/codet5-base/ov
{'message': 'OK', 'method': 'POST', 'status-code': 200, 'timestamp': '2023-12-13T00:47:16.114959', 'url': 'http://localhost:8000/huggingface_models/codet5-base/ov', 'data': {'model-type': 'Codet5_base', 'input_text': 'print("Hello, world!")', 'prediction': {'prediction': 't r y { c'}}}
Inference successful!
{'prediction': 't r y { c'}
___________________________________
Endpoint: http://localhost:8000/huggingface_models/codet5-base/ov
{'message': 'OK', 'method': 'POST', 'status-code': 200, 'timestamp': '2023-12-13T00:47:21.242028', 'url': 'http://localhost:8000/huggingface_models/codet5-base/ov', 'data': {'model-type': 'Codet5_base', 'input_text': 'if x > 5:', 'prediction': {'prediction': 'c ase x : c'}}}
Inference successful!
{'prediction': 'c ase x : c'}


CodeCarbon Results: results/emissions_codet5-base.csv
------------------------------

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Running experiment infrastructure -> ov, model -> codet5p-220, dataset -> testing/inputs.txt, reps -> 1

------------------------------

---------------- Rep 1 out of 1: 

Running POST requests infrastructure -> ov, model -> codet5p-220, dataset -> testing/inputs.txt

Dataset: ['def hello_world():', 'for i in range(10):', 'print("Hello, world!")', 'if x > 5:']
---
Running POST requests infrastructure -> ov, model -> codet5p-220, dataset -> ['def hello_world():', 'for i in range(10):', 'print("Hello, world!")', 'if x > 5:']

___________________________________
Endpoint: http://localhost:8000/huggingface_models/codet5p-220/ov
{'message': 'OK', 'method': 'POST', 'status-code': 200, 'timestamp': '2023-12-13T00:47:37.454369', 'url': 'http://localhost:8000/huggingface_models/codet5p-220/ov', 'data': {'model-type': 'Codet5p_220m', 'input_text': 'def hello_world():', 'prediction': {'prediction': '\n    print "Hello world!"\n\ndef main():\n    print "Hello world'}}}
Inference successful!
{'prediction': '\n    print "Hello world!"\n\ndef main():\n    print "Hello world'}
___________________________________
Endpoint: http://localhost:8000/huggingface_models/codet5p-220/ov
{'message': 'OK', 'method': 'POST', 'status-code': 200, 'timestamp': '2023-12-13T00:47:43.446877', 'url': 'http://localhost:8000/huggingface_models/codet5p-220/ov', 'data': {'model-type': 'Codet5p_220m', 'input_text': 'for i in range(10):', 'prediction': {'prediction': '\n# Copyright (c) 2012-2014 The Bitcoin developers\n# Distributed under the'}}}
Inference successful!
{'prediction': '\n# Copyright (c) 2012-2014 The Bitcoin developers\n# Distributed under the'}
___________________________________
Endpoint: http://localhost:8000/huggingface_models/codet5p-220/ov
{'message': 'OK', 'method': 'POST', 'status-code': 200, 'timestamp': '2023-12-13T00:47:49.378325', 'url': 'http://localhost:8000/huggingface_models/codet5p-220/ov', 'data': {'model-type': 'Codet5p_220m', 'input_text': 'print("Hello, world!")', 'prediction': {'prediction': '\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n'}}}
Inference successful!
{'prediction': '\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n'}
___________________________________
Endpoint: http://localhost:8000/huggingface_models/codet5p-220/ov
{'message': 'OK', 'method': 'POST', 'status-code': 200, 'timestamp': '2023-12-13T00:47:55.214898', 'url': 'http://localhost:8000/huggingface_models/codet5p-220/ov', 'data': {'model-type': 'Codet5p_220m', 'input_text': 'if x > 5:', 'prediction': {'prediction': '\n#include "../include/c_stdlib.h"\n#include "'}}}
Inference successful!
{'prediction': '\n#include "../include/c_stdlib.h"\n#include "'}


CodeCarbon Results: results/emissions_codet5p-220.csv
------------------------------

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Running experiment infrastructure -> ov, model -> gpt-neo-125m, dataset -> testing/inputs.txt, reps -> 1

------------------------------

---------------- Rep 1 out of 1: 

Running POST requests infrastructure -> ov, model -> gpt-neo-125m, dataset -> testing/inputs.txt

Dataset: ['def hello_world():', 'for i in range(10):', 'print("Hello, world!")', 'if x > 5:']
---
Running POST requests infrastructure -> ov, model -> gpt-neo-125m, dataset -> ['def hello_world():', 'for i in range(10):', 'print("Hello, world!")', 'if x > 5:']

___________________________________
Endpoint: http://localhost:8000/huggingface_models/gpt-neo-125m/ov
{'message': 'OK', 'method': 'POST', 'status-code': 200, 'timestamp': '2023-12-13T00:48:04.094978', 'url': 'http://localhost:8000/huggingface_models/gpt-neo-125m/ov', 'data': {'model-type': 'GPT_Neo_125m', 'input_text': 'def hello_world():', 'prediction': {'prediction': 'def hello_world():\n              '}}}
Inference successful!
{'prediction': 'def hello_world():\n              '}
___________________________________
Endpoint: http://localhost:8000/huggingface_models/gpt-neo-125m/ov
{'message': 'OK', 'method': 'POST', 'status-code': 200, 'timestamp': '2023-12-13T00:48:07.562282', 'url': 'http://localhost:8000/huggingface_models/gpt-neo-125m/ov', 'data': {'model-type': 'GPT_Neo_125m', 'input_text': 'for i in range(10):', 'prediction': {'prediction': 'for i in range(10):\n            '}}}
Inference successful!
{'prediction': 'for i in range(10):\n            '}
___________________________________
Endpoint: http://localhost:8000/huggingface_models/gpt-neo-125m/ov
{'message': 'OK', 'method': 'POST', 'status-code': 200, 'timestamp': '2023-12-13T00:48:10.976668', 'url': 'http://localhost:8000/huggingface_models/gpt-neo-125m/ov', 'data': {'model-type': 'GPT_Neo_125m', 'input_text': 'print("Hello, world!")', 'prediction': {'prediction': 'print("Hello, world!")\n            '}}}
Inference successful!
{'prediction': 'print("Hello, world!")\n            '}
___________________________________
Endpoint: http://localhost:8000/huggingface_models/gpt-neo-125m/ov
{'message': 'OK', 'method': 'POST', 'status-code': 200, 'timestamp': '2023-12-13T00:48:14.433909', 'url': 'http://localhost:8000/huggingface_models/gpt-neo-125m/ov', 'data': {'model-type': 'GPT_Neo_125m', 'input_text': 'if x > 5:', 'prediction': {'prediction': 'if x > 5:\n              '}}}
Inference successful!
{'prediction': 'if x > 5:\n              '}


CodeCarbon Results: results/emissions_gpt-neo-125m.csv
------------------------------

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Running experiment infrastructure -> ov, model -> codeparrot-small, dataset -> testing/inputs.txt, reps -> 1

------------------------------

---------------- Rep 1 out of 1: 

Running POST requests infrastructure -> ov, model -> codeparrot-small, dataset -> testing/inputs.txt

Dataset: ['def hello_world():', 'for i in range(10):', 'print("Hello, world!")', 'if x > 5:']
---
Running POST requests infrastructure -> ov, model -> codeparrot-small, dataset -> ['def hello_world():', 'for i in range(10):', 'print("Hello, world!")', 'if x > 5:']

___________________________________
Endpoint: http://localhost:8000/huggingface_models/codeparrot-small/ov
{'message': 'OK', 'method': 'POST', 'status-code': 200, 'timestamp': '2023-12-13T00:48:23.328477', 'url': 'http://localhost:8000/huggingface_models/codeparrot-small/ov', 'data': {'model-type': 'CodeParrot_small', 'input_text': 'def hello_world():', 'prediction': {'prediction': 'def hello_world():\n    return "Hello World!"\n\ndef hello_world_with_'}}}
Inference successful!
{'prediction': 'def hello_world():\n    return "Hello World!"\n\ndef hello_world_with_'}
___________________________________
Endpoint: http://localhost:8000/huggingface_models/codeparrot-small/ov
{'message': 'OK', 'method': 'POST', 'status-code': 200, 'timestamp': '2023-12-13T00:48:28.586272', 'url': 'http://localhost:8000/huggingface_models/codeparrot-small/ov', 'data': {'model-type': 'CodeParrot_small', 'input_text': 'for i in range(10):', 'prediction': {'prediction': 'for i in range(10):\n            self.assertEqual(self.get_response(i),'}}}
Inference successful!
{'prediction': 'for i in range(10):\n            self.assertEqual(self.get_response(i),'}
___________________________________
Endpoint: http://localhost:8000/huggingface_models/codeparrot-small/ov
{'message': 'OK', 'method': 'POST', 'status-code': 200, 'timestamp': '2023-12-13T00:48:33.859765', 'url': 'http://localhost:8000/huggingface_models/codeparrot-small/ov', 'data': {'model-type': 'CodeParrot_small', 'input_text': 'print("Hello, world!")', 'prediction': {'prediction': 'print("Hello, world!")\n        self.assertEqual(self.client.get("/hello/world'}}}
Inference successful!
{'prediction': 'print("Hello, world!")\n        self.assertEqual(self.client.get("/hello/world'}
___________________________________
Endpoint: http://localhost:8000/huggingface_models/codeparrot-small/ov
{'message': 'OK', 'method': 'POST', 'status-code': 200, 'timestamp': '2023-12-13T00:48:39.186367', 'url': 'http://localhost:8000/huggingface_models/codeparrot-small/ov', 'data': {'model-type': 'CodeParrot_small', 'input_text': 'if x > 5:', 'prediction': {'prediction': 'if x > 5:\n        return False\n    if x < 10:\n        return False\n    if x'}}}
Inference successful!
{'prediction': 'if x > 5:\n        return False\n    if x < 10:\n        return False\n    if x'}


CodeCarbon Results: results/emissions_codeparrot-small.csv
------------------------------

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Running experiment infrastructure -> ov, model -> pythia-410m, dataset -> testing/inputs.txt, reps -> 1

------------------------------

---------------- Rep 1 out of 1: 

Running POST requests infrastructure -> ov, model -> pythia-410m, dataset -> testing/inputs.txt

Dataset: ['def hello_world():', 'for i in range(10):', 'print("Hello, world!")', 'if x > 5:']
---
Running POST requests infrastructure -> ov, model -> pythia-410m, dataset -> ['def hello_world():', 'for i in range(10):', 'print("Hello, world!")', 'if x > 5:']

___________________________________
Endpoint: http://localhost:8000/huggingface_models/pythia-410m/ov
{'message': 'OK', 'method': 'POST', 'status-code': 200, 'timestamp': '2023-12-13T00:49:06.622422', 'url': 'http://localhost:8000/huggingface_models/pythia-410m/ov', 'data': {'model-type': 'Pythia_410m', 'input_text': 'def hello_world():', 'prediction': {'prediction': 'def hello_world():\n        print("Hello World")\n\nif __name__ == "'}}}
Inference successful!
{'prediction': 'def hello_world():\n        print("Hello World")\n\nif __name__ == "'}
___________________________________
Endpoint: http://localhost:8000/huggingface_models/pythia-410m/ov
{'message': 'OK', 'method': 'POST', 'status-code': 200, 'timestamp': '2023-12-13T00:49:16.331002', 'url': 'http://localhost:8000/huggingface_models/pythia-410m/ov', 'data': {'model-type': 'Pythia_410m', 'input_text': 'for i in range(10):', 'prediction': {'prediction': 'for i in range(10):\n        if i % 10 == 0:\n            print('}}}
Inference successful!
{'prediction': 'for i in range(10):\n        if i % 10 == 0:\n            print('}
___________________________________
Endpoint: http://localhost:8000/huggingface_models/pythia-410m/ov
{'message': 'OK', 'method': 'POST', 'status-code': 200, 'timestamp': '2023-12-13T00:49:25.509975', 'url': 'http://localhost:8000/huggingface_models/pythia-410m/ov', 'data': {'model-type': 'Pythia_410m', 'input_text': 'print("Hello, world!")', 'prediction': {'prediction': 'print("Hello, world!")\n\nA:\n\nYou can use the following code:'}}}
Inference successful!
{'prediction': 'print("Hello, world!")\n\nA:\n\nYou can use the following code:'}
___________________________________
Endpoint: http://localhost:8000/huggingface_models/pythia-410m/ov
{'message': 'OK', 'method': 'POST', 'status-code': 200, 'timestamp': '2023-12-13T00:49:34.988911', 'url': 'http://localhost:8000/huggingface_models/pythia-410m/ov', 'data': {'model-type': 'Pythia_410m', 'input_text': 'if x > 5:', 'prediction': {'prediction': 'if x > 5:\n            print("You have reached the maximum number of characters in the file'}}}
Inference successful!
{'prediction': 'if x > 5:\n            print("You have reached the maximum number of characters in the file'}


CodeCarbon Results: results/emissions_pythia-410m.csv
------------------------------

